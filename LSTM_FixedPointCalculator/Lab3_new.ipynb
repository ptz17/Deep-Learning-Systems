{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 3: Build fixpoint calculator using LSTM Networks\n",
    "# Tara Zamani \n",
    "\n",
    "from random import seed\n",
    "from random import randint\n",
    "from random import uniform\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from math import log10\n",
    "from math import sqrt\n",
    "from numpy import argmax\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "# Dataset preparation (format)\n",
    "# 0) Let's use [9:5]_2.[4:0]_2 as the UN-SIGNED fix-point representation \n",
    "#    for example, 01000.10000 = 2^3.5 = 8.5 (UPDATED: NOW totally 10 bits)\n",
    "# Requirement\n",
    "# 1) Need to have seperate functions, including (check out bracket-2 in lab3-demo)\n",
    "#    1-a) data generation\n",
    "#    1-b) data conversion and inversion (inversion for inference/testing use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "# convert all list elements from floating point to 10-bit fixed point\n",
    "def num_to_fixed(input_list):\n",
    "    ans = []\n",
    "    for i in input_list:\n",
    "        #tansforming floating point number to an integer by shifting decimal 5 digits to the right\n",
    "        temp = int(i * 32)\n",
    "        fixed_num = \"\"\n",
    "        for digit in range(10):\n",
    "            if (temp%2 == 0):\n",
    "                fixed_num = '0' + fixed_num\n",
    "            else:\n",
    "                fixed_num = '1' + fixed_num\n",
    "            temp = int(temp / 2) \n",
    "        ans.append(fixed_num)\n",
    "    return ans\n",
    "\n",
    "# convert from 10-bit fixed point string to floating point\n",
    "def fixed_to_num(string):\n",
    "    ans = \"\"\n",
    "    if '+' in string: # --> inverting x\n",
    "        a,b = string.split('+')\n",
    "        num1, num2 = 0, 0\n",
    "        for i in range(10):\n",
    "            num1 += float(int(a[i])*2**(4-i))\n",
    "            num2 += float(int(b[i])*2**(4-i))\n",
    "        ans = str(num1) + \"+\" + str(num2)\n",
    "    else: # --> inverting y\n",
    "        num = 0\n",
    "        for i in range(10):\n",
    "            num += float(int(string[i])*2**(4-i))\n",
    "        ans = str(num)    \n",
    "    return ans\n",
    "\n",
    "# generate lists of random 10-bit fixed point numbers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "    X, y = list(), list()\n",
    "    for i in range(n_examples):\n",
    "        # generate floating point numbers by separetely creating the 5-bit decimal and mantissa\n",
    "        in_pattern = [(float(randint(1, largest)) + randint(1, largest)/32.0) for _ in range(n_numbers)]\n",
    "        out_pattern = sum(in_pattern)\n",
    "        X.append(in_pattern)\n",
    "        y.append(out_pattern)\n",
    "    return X, y\n",
    "\n",
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "    max_length = 21\n",
    "    Xstr = list()\n",
    "    for pattern in X:\n",
    "        strp = '+'.join([str(n) for n in pattern])\n",
    "        strp = ''.join([' ' for _ in range(int(max_length-len(strp)))]) + strp\n",
    "        Xstr.append(strp)\n",
    "    max_length = 10\n",
    "    ystr = list()\n",
    "    for pattern in y:\n",
    "        strp = str(pattern)\n",
    "        strp = ''.join([' ' for _ in range(int(max_length-len(strp)))]) + strp\n",
    "        ystr.append(strp)\n",
    "    return Xstr, ystr\n",
    "\n",
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    Xenc = list()\n",
    "    for pattern in X:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        Xenc.append(integer_encoded)\n",
    "    yenc = list()\n",
    "    for pattern in y:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        yenc.append(integer_encoded)\n",
    "    return Xenc, yenc\n",
    " \n",
    "# one hot encode\n",
    "def one_hot_encode(X, y, max_int):\n",
    "    Xenc = list()\n",
    "    for seq in X:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        Xenc.append(pattern)\n",
    "    yenc = list()\n",
    "    for seq in y:\n",
    "        pattern = list()\n",
    "        for index in seq:\n",
    "            vector = [0 for _ in range(max_int)]\n",
    "            vector[index] = 1\n",
    "            pattern.append(vector)\n",
    "        yenc.append(pattern)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an encoded dataset\n",
    "def generate_data(n_samples, n_numbers, largest, alphabet):\n",
    "    # generate pairs\n",
    "    X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "    # convert floating point list to fixed point list\n",
    "    X = [num_to_fixed(a) for a in X]\n",
    "    y = num_to_fixed(y)\n",
    "    # convert to strings\n",
    "    X, y = to_string(X, y, n_numbers, largest)\n",
    "    # integer encode\n",
    "    X, y = integer_encode(X, y, alphabet)\n",
    "    # one hot encode\n",
    "    X, y = one_hot_encode(X, y, len(alphabet))\n",
    "    # return as numpy arrays\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y\n",
    "\n",
    "# invert encoding\n",
    "def invert(seq, alphabet):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    strings = list()\n",
    "    for pattern in seq:\n",
    "        string = int_to_char[argmax(pattern)]\n",
    "        strings.append(string)\n",
    "    fixedpnt_str = ''.join(strings)\n",
    "    return fixed_to_num(fixedpnt_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "seed(1)\n",
    "n_samples = 1000\n",
    "n_numbers = 2\n",
    "largest = 16\n",
    "#alphabet = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', ' ', '.']\n",
    "alphabet = ['0', '1', '+', ' ']\n",
    "n_chars = len(alphabet)\n",
    "n_in_seq_length = 21 #13\n",
    "n_out_seq_length = 10 #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTrain\n",
      " [[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]] \n",
      "YTrain\n",
      " [[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n",
      "\n",
      "Inverted XTrain 5.09375+9.125 \n",
      "Inverted YTrain 14.21875\n",
      "\n",
      "EX2:\n",
      "XTrain\n",
      " [[0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]] \n",
      "YTrain\n",
      " [[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]]\n",
      "\n",
      "Inverted XTrain 16.46875+16.40625 \n",
      "Inverted YTrain 0.875\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = generate_data(n_samples, n_numbers, largest, alphabet)\n",
    "# check your dataset sample\n",
    "print(\"XTrain\\n\",X_train[0],\"\\nYTrain\\n\",y_train[0])\n",
    "print(\"\\nInverted XTrain\",invert(X_train[0],alphabet),\"\\nInverted YTrain\",invert(y_train[0],alphabet))\n",
    "# check your dataset sample\n",
    "print(\"\\nEX2:\\nXTrain\\n\",X_train[1],\"\\nYTrain\\n\",y_train[1])\n",
    "print(\"\\nInverted XTrain\",invert(X_train[1],alphabet),\"\\nInverted YTrain\",invert(y_train[1],alphabet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2\n",
    "# Build and Train a TWO-LAYER LSTM Network (two stacked LSTM).\n",
    "# 1) Feel free to use any optimizers, normlization techniques, decaying, etc., techniques\n",
    "# 2) Your training dataset should be LESS THAN 50% of the total data points\n",
    "# 3) In the testing phase, you should implement (check out bracekt-8 in lab3-demo)\n",
    "#  3-a) Inference with accuracy as metrics\n",
    "#. 3-b) Inference with MSE as metrics\n",
    "#. 3-c) Showing at least 50 cases (individual inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                17664     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 10, 32)            12416     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 4)             132       \n",
      "=================================================================\n",
      "Total params: 30,212\n",
      "Trainable params: 30,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define LSTM configuration\n",
    "n_batch = 20\n",
    "n_epoch = 400\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(int(n_out_seq_length)))\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/400\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 0.8691 - accuracy: 0.5056\n",
      "Epoch 2/400\n",
      "1000/1000 [==============================] - 1s 828us/sample - loss: 0.6971 - accuracy: 0.5114\n",
      "Epoch 3/400\n",
      "1000/1000 [==============================] - 1s 850us/sample - loss: 0.6946 - accuracy: 0.5132\n",
      "Epoch 4/400\n",
      "1000/1000 [==============================] - 1s 825us/sample - loss: 0.6938 - accuracy: 0.5102\n",
      "Epoch 5/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6935 - accuracy: 0.5114\n",
      "Epoch 6/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6926 - accuracy: 0.5162\n",
      "Epoch 7/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6930 - accuracy: 0.5110\n",
      "Epoch 8/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6926 - accuracy: 0.5112\n",
      "Epoch 9/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6924 - accuracy: 0.5099\n",
      "Epoch 10/400\n",
      "1000/1000 [==============================] - 1s 995us/sample - loss: 0.6924 - accuracy: 0.5156\n",
      "Epoch 11/400\n",
      "1000/1000 [==============================] - 1s 837us/sample - loss: 0.6923 - accuracy: 0.5105\n",
      "Epoch 12/400\n",
      "1000/1000 [==============================] - 1s 783us/sample - loss: 0.6924 - accuracy: 0.5088\n",
      "Epoch 13/400\n",
      "1000/1000 [==============================] - 1s 856us/sample - loss: 0.6924 - accuracy: 0.5126\n",
      "Epoch 14/400\n",
      "1000/1000 [==============================] - 1s 850us/sample - loss: 0.6918 - accuracy: 0.5195\n",
      "Epoch 15/400\n",
      "1000/1000 [==============================] - 1s 888us/sample - loss: 0.6927 - accuracy: 0.5074\n",
      "Epoch 16/400\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.6923 - accuracy: 0.5079\n",
      "Epoch 17/400\n",
      "1000/1000 [==============================] - 1s 709us/sample - loss: 0.6920 - accuracy: 0.5137\n",
      "Epoch 18/400\n",
      "1000/1000 [==============================] - 1s 728us/sample - loss: 0.6915 - accuracy: 0.5202\n",
      "Epoch 19/400\n",
      "1000/1000 [==============================] - 1s 765us/sample - loss: 0.6920 - accuracy: 0.5106\n",
      "Epoch 20/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6912 - accuracy: 0.5173\n",
      "Epoch 21/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6917 - accuracy: 0.5191\n",
      "Epoch 22/400\n",
      "1000/1000 [==============================] - 1s 961us/sample - loss: 0.6917 - accuracy: 0.5144\n",
      "Epoch 23/400\n",
      "1000/1000 [==============================] - 1s 958us/sample - loss: 0.6916 - accuracy: 0.5190\n",
      "Epoch 24/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6915 - accuracy: 0.5104\n",
      "Epoch 25/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6899 - accuracy: 0.5107\n",
      "Epoch 26/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6879 - accuracy: 0.5148\n",
      "Epoch 27/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6858 - accuracy: 0.5291\n",
      "Epoch 28/400\n",
      "1000/1000 [==============================] - 1s 907us/sample - loss: 0.6865 - accuracy: 0.5164\n",
      "Epoch 29/400\n",
      "1000/1000 [==============================] - 1s 890us/sample - loss: 0.6803 - accuracy: 0.5326\n",
      "Epoch 30/400\n",
      "1000/1000 [==============================] - 1s 859us/sample - loss: 0.6797 - accuracy: 0.5234\n",
      "Epoch 31/400\n",
      "1000/1000 [==============================] - 1s 888us/sample - loss: 0.6781 - accuracy: 0.5259\n",
      "Epoch 32/400\n",
      "1000/1000 [==============================] - 1s 879us/sample - loss: 0.6773 - accuracy: 0.5330\n",
      "Epoch 33/400\n",
      "1000/1000 [==============================] - 1s 902us/sample - loss: 0.6775 - accuracy: 0.5308\n",
      "Epoch 34/400\n",
      "1000/1000 [==============================] - 1s 872us/sample - loss: 0.6773 - accuracy: 0.5249\n",
      "Epoch 35/400\n",
      "1000/1000 [==============================] - 1s 860us/sample - loss: 0.6777 - accuracy: 0.5273\n",
      "Epoch 36/400\n",
      "1000/1000 [==============================] - 1s 872us/sample - loss: 0.6779 - accuracy: 0.5213\n",
      "Epoch 37/400\n",
      "1000/1000 [==============================] - 1s 891us/sample - loss: 0.6771 - accuracy: 0.5327\n",
      "Epoch 38/400\n",
      "1000/1000 [==============================] - 1s 893us/sample - loss: 0.6775 - accuracy: 0.5291\n",
      "Epoch 39/400\n",
      "1000/1000 [==============================] - 1s 888us/sample - loss: 0.6761 - accuracy: 0.5278\n",
      "Epoch 40/400\n",
      "1000/1000 [==============================] - 1s 911us/sample - loss: 0.6763 - accuracy: 0.5294\n",
      "Epoch 41/400\n",
      "1000/1000 [==============================] - 1s 924us/sample - loss: 0.6774 - accuracy: 0.5255\n",
      "Epoch 42/400\n",
      "1000/1000 [==============================] - 1s 910us/sample - loss: 0.6766 - accuracy: 0.5186\n",
      "Epoch 43/400\n",
      "1000/1000 [==============================] - 1s 939us/sample - loss: 0.6763 - accuracy: 0.5335\n",
      "Epoch 44/400\n",
      "1000/1000 [==============================] - 1s 932us/sample - loss: 0.6764 - accuracy: 0.5255\n",
      "Epoch 45/400\n",
      "1000/1000 [==============================] - 1s 891us/sample - loss: 0.6761 - accuracy: 0.5303\n",
      "Epoch 46/400\n",
      "1000/1000 [==============================] - 1s 898us/sample - loss: 0.6764 - accuracy: 0.5295\n",
      "Epoch 47/400\n",
      "1000/1000 [==============================] - 1s 910us/sample - loss: 0.6764 - accuracy: 0.5297\n",
      "Epoch 48/400\n",
      "1000/1000 [==============================] - 1s 886us/sample - loss: 0.6758 - accuracy: 0.5267\n",
      "Epoch 49/400\n",
      "1000/1000 [==============================] - 1s 911us/sample - loss: 0.6764 - accuracy: 0.5256\n",
      "Epoch 50/400\n",
      "1000/1000 [==============================] - 1s 937us/sample - loss: 0.6770 - accuracy: 0.5253\n",
      "Epoch 51/400\n",
      "1000/1000 [==============================] - 1s 898us/sample - loss: 0.6773 - accuracy: 0.5290\n",
      "Epoch 52/400\n",
      "1000/1000 [==============================] - 1s 889us/sample - loss: 0.6764 - accuracy: 0.5252\n",
      "Epoch 53/400\n",
      "1000/1000 [==============================] - 1s 816us/sample - loss: 0.6768 - accuracy: 0.5288\n",
      "Epoch 54/400\n",
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.6753 - accuracy: 0.5279\n",
      "Epoch 55/400\n",
      "1000/1000 [==============================] - 1s 997us/sample - loss: 0.6757 - accuracy: 0.5287\n",
      "Epoch 56/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6771 - accuracy: 0.5241\n",
      "Epoch 57/400\n",
      "1000/1000 [==============================] - 1s 975us/sample - loss: 0.6749 - accuracy: 0.5323\n",
      "Epoch 58/400\n",
      "1000/1000 [==============================] - 1s 949us/sample - loss: 0.6755 - accuracy: 0.5335\n",
      "Epoch 59/400\n",
      "1000/1000 [==============================] - 1s 873us/sample - loss: 0.6769 - accuracy: 0.5346\n",
      "Epoch 60/400\n",
      "1000/1000 [==============================] - 1s 895us/sample - loss: 0.6756 - accuracy: 0.5244\n",
      "Epoch 61/400\n",
      "1000/1000 [==============================] - 1s 929us/sample - loss: 0.6755 - accuracy: 0.5275\n",
      "Epoch 62/400\n",
      "1000/1000 [==============================] - 1s 881us/sample - loss: 0.6749 - accuracy: 0.5243\n",
      "Epoch 63/400\n",
      "1000/1000 [==============================] - 1s 919us/sample - loss: 0.6741 - accuracy: 0.5319\n",
      "Epoch 64/400\n",
      "1000/1000 [==============================] - 1s 944us/sample - loss: 0.6744 - accuracy: 0.5357\n",
      "Epoch 65/400\n",
      "1000/1000 [==============================] - 1s 823us/sample - loss: 0.6730 - accuracy: 0.5362\n",
      "Epoch 66/400\n",
      "1000/1000 [==============================] - 1s 862us/sample - loss: 0.6709 - accuracy: 0.5418\n",
      "Epoch 67/400\n",
      "1000/1000 [==============================] - 1s 872us/sample - loss: 0.6716 - accuracy: 0.5382\n",
      "Epoch 68/400\n",
      "1000/1000 [==============================] - 1s 830us/sample - loss: 0.6664 - accuracy: 0.5367\n",
      "Epoch 69/400\n",
      "1000/1000 [==============================] - 1s 853us/sample - loss: 0.6627 - accuracy: 0.5503\n",
      "Epoch 70/400\n",
      "1000/1000 [==============================] - 1s 879us/sample - loss: 0.6517 - accuracy: 0.5687\n",
      "Epoch 71/400\n",
      "1000/1000 [==============================] - 1s 876us/sample - loss: 0.6415 - accuracy: 0.5739\n",
      "Epoch 72/400\n",
      "1000/1000 [==============================] - 1s 868us/sample - loss: 0.6346 - accuracy: 0.5759\n",
      "Epoch 73/400\n",
      "1000/1000 [==============================] - 1s 853us/sample - loss: 0.6304 - accuracy: 0.5780\n",
      "Epoch 74/400\n",
      "1000/1000 [==============================] - 1s 814us/sample - loss: 0.6231 - accuracy: 0.5830\n",
      "Epoch 75/400\n",
      "1000/1000 [==============================] - 1s 871us/sample - loss: 0.6228 - accuracy: 0.5839\n",
      "Epoch 76/400\n",
      "1000/1000 [==============================] - 1s 882us/sample - loss: 0.6141 - accuracy: 0.5901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/400\n",
      "1000/1000 [==============================] - 1s 782us/sample - loss: 0.6147 - accuracy: 0.5906\n",
      "Epoch 78/400\n",
      "1000/1000 [==============================] - 1s 793us/sample - loss: 0.6062 - accuracy: 0.5935\n",
      "Epoch 79/400\n",
      "1000/1000 [==============================] - 1s 832us/sample - loss: 0.6087 - accuracy: 0.5921\n",
      "Epoch 80/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6129 - accuracy: 0.5877\n",
      "Epoch 81/400\n",
      "1000/1000 [==============================] - 1s 797us/sample - loss: 0.6101 - accuracy: 0.5905\n",
      "Epoch 82/400\n",
      "1000/1000 [==============================] - 1s 826us/sample - loss: 0.5974 - accuracy: 0.6027\n",
      "Epoch 83/400\n",
      "1000/1000 [==============================] - 1s 809us/sample - loss: 0.5945 - accuracy: 0.6001\n",
      "Epoch 84/400\n",
      "1000/1000 [==============================] - 1s 979us/sample - loss: 0.5968 - accuracy: 0.6003\n",
      "Epoch 85/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5908 - accuracy: 0.6046\n",
      "Epoch 86/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5824 - accuracy: 0.6223\n",
      "Epoch 87/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5820 - accuracy: 0.6230\n",
      "Epoch 88/400\n",
      "1000/1000 [==============================] - 1s 921us/sample - loss: 0.5804 - accuracy: 0.6179\n",
      "Epoch 89/400\n",
      "1000/1000 [==============================] - 1s 796us/sample - loss: 0.5871 - accuracy: 0.6216\n",
      "Epoch 90/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5788 - accuracy: 0.6294\n",
      "Epoch 91/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5734 - accuracy: 0.6295\n",
      "Epoch 92/400\n",
      "1000/1000 [==============================] - 1s 1000us/sample - loss: 0.5754 - accuracy: 0.6317\n",
      "Epoch 93/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5721 - accuracy: 0.6319\n",
      "Epoch 94/400\n",
      "1000/1000 [==============================] - 1s 899us/sample - loss: 0.5619 - accuracy: 0.6454\n",
      "Epoch 95/400\n",
      "1000/1000 [==============================] - 1s 902us/sample - loss: 0.5833 - accuracy: 0.6215\n",
      "Epoch 96/400\n",
      "1000/1000 [==============================] - 1s 893us/sample - loss: 0.5683 - accuracy: 0.6334\n",
      "Epoch 97/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5658 - accuracy: 0.6324\n",
      "Epoch 98/400\n",
      "1000/1000 [==============================] - 1s 859us/sample - loss: 0.5617 - accuracy: 0.6360\n",
      "Epoch 99/400\n",
      "1000/1000 [==============================] - 1s 831us/sample - loss: 0.5702 - accuracy: 0.6295\n",
      "Epoch 100/400\n",
      "1000/1000 [==============================] - 1s 810us/sample - loss: 0.5742 - accuracy: 0.6311\n",
      "Epoch 101/400\n",
      "1000/1000 [==============================] - 1s 784us/sample - loss: 0.5507 - accuracy: 0.6486\n",
      "Epoch 102/400\n",
      "1000/1000 [==============================] - 1s 835us/sample - loss: 0.5524 - accuracy: 0.6475\n",
      "Epoch 103/400\n",
      "1000/1000 [==============================] - 1s 802us/sample - loss: 0.5533 - accuracy: 0.6469\n",
      "Epoch 104/400\n",
      "1000/1000 [==============================] - 1s 796us/sample - loss: 0.5427 - accuracy: 0.6535\n",
      "Epoch 105/400\n",
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.5362 - accuracy: 0.6581\n",
      "Epoch 106/400\n",
      "1000/1000 [==============================] - 1s 811us/sample - loss: 0.5467 - accuracy: 0.6513\n",
      "Epoch 107/400\n",
      "1000/1000 [==============================] - 1s 814us/sample - loss: 0.5455 - accuracy: 0.6530\n",
      "Epoch 108/400\n",
      "1000/1000 [==============================] - 1s 802us/sample - loss: 0.5448 - accuracy: 0.6511\n",
      "Epoch 109/400\n",
      "1000/1000 [==============================] - 1s 817us/sample - loss: 0.5430 - accuracy: 0.6452\n",
      "Epoch 110/400\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.5366 - accuracy: 0.6537\n",
      "Epoch 111/400\n",
      "1000/1000 [==============================] - 1s 824us/sample - loss: 0.5303 - accuracy: 0.6624\n",
      "Epoch 112/400\n",
      "1000/1000 [==============================] - 1s 778us/sample - loss: 0.5415 - accuracy: 0.6510\n",
      "Epoch 113/400\n",
      "1000/1000 [==============================] - 1s 772us/sample - loss: 0.5273 - accuracy: 0.6645\n",
      "Epoch 114/400\n",
      "1000/1000 [==============================] - 1s 815us/sample - loss: 0.5241 - accuracy: 0.6650\n",
      "Epoch 115/400\n",
      "1000/1000 [==============================] - 1s 947us/sample - loss: 0.5288 - accuracy: 0.6674\n",
      "Epoch 116/400\n",
      "1000/1000 [==============================] - 1s 878us/sample - loss: 0.5235 - accuracy: 0.6734\n",
      "Epoch 117/400\n",
      "1000/1000 [==============================] - 1s 823us/sample - loss: 0.5279 - accuracy: 0.6658\n",
      "Epoch 118/400\n",
      "1000/1000 [==============================] - 1s 824us/sample - loss: 0.5264 - accuracy: 0.6647\n",
      "Epoch 119/400\n",
      "1000/1000 [==============================] - 1s 810us/sample - loss: 0.5184 - accuracy: 0.6681\n",
      "Epoch 120/400\n",
      "1000/1000 [==============================] - 1s 819us/sample - loss: 0.5384 - accuracy: 0.6531\n",
      "Epoch 121/400\n",
      "1000/1000 [==============================] - 1s 812us/sample - loss: 0.5301 - accuracy: 0.6597\n",
      "Epoch 122/400\n",
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.5108 - accuracy: 0.6748\n",
      "Epoch 123/400\n",
      "1000/1000 [==============================] - 1s 815us/sample - loss: 0.5172 - accuracy: 0.6643\n",
      "Epoch 124/400\n",
      "1000/1000 [==============================] - 1s 812us/sample - loss: 0.5118 - accuracy: 0.6760\n",
      "Epoch 125/400\n",
      "1000/1000 [==============================] - 1s 808us/sample - loss: 0.5303 - accuracy: 0.6663\n",
      "Epoch 126/400\n",
      "1000/1000 [==============================] - 1s 776us/sample - loss: 0.5341 - accuracy: 0.6591\n",
      "Epoch 127/400\n",
      "1000/1000 [==============================] - 1s 824us/sample - loss: 0.5102 - accuracy: 0.6830\n",
      "Epoch 128/400\n",
      "1000/1000 [==============================] - 1s 803us/sample - loss: 0.5034 - accuracy: 0.6791\n",
      "Epoch 129/400\n",
      "1000/1000 [==============================] - 1s 816us/sample - loss: 0.5100 - accuracy: 0.6754\n",
      "Epoch 130/400\n",
      "1000/1000 [==============================] - 1s 789us/sample - loss: 0.5095 - accuracy: 0.6789\n",
      "Epoch 131/400\n",
      "1000/1000 [==============================] - 1s 768us/sample - loss: 0.5096 - accuracy: 0.6790\n",
      "Epoch 132/400\n",
      "1000/1000 [==============================] - 1s 814us/sample - loss: 0.5189 - accuracy: 0.6709\n",
      "Epoch 133/400\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.4947 - accuracy: 0.6910\n",
      "Epoch 134/400\n",
      "1000/1000 [==============================] - 1s 827us/sample - loss: 0.4922 - accuracy: 0.6905\n",
      "Epoch 135/400\n",
      "1000/1000 [==============================] - 1s 823us/sample - loss: 0.5032 - accuracy: 0.6803\n",
      "Epoch 136/400\n",
      "1000/1000 [==============================] - 1s 823us/sample - loss: 0.4956 - accuracy: 0.6900\n",
      "Epoch 137/400\n",
      "1000/1000 [==============================] - 1s 797us/sample - loss: 0.4957 - accuracy: 0.6835\n",
      "Epoch 138/400\n",
      "1000/1000 [==============================] - 1s 827us/sample - loss: 0.4927 - accuracy: 0.6860\n",
      "Epoch 139/400\n",
      "1000/1000 [==============================] - 1s 779us/sample - loss: 0.5257 - accuracy: 0.6638\n",
      "Epoch 140/400\n",
      "1000/1000 [==============================] - 1s 855us/sample - loss: 0.4895 - accuracy: 0.6962\n",
      "Epoch 141/400\n",
      "1000/1000 [==============================] - 1s 842us/sample - loss: 0.4906 - accuracy: 0.6898\n",
      "Epoch 142/400\n",
      "1000/1000 [==============================] - 1s 804us/sample - loss: 0.4858 - accuracy: 0.6958\n",
      "Epoch 143/400\n",
      "1000/1000 [==============================] - 1s 803us/sample - loss: 0.5008 - accuracy: 0.6841\n",
      "Epoch 144/400\n",
      "1000/1000 [==============================] - 1s 835us/sample - loss: 0.5112 - accuracy: 0.6743\n",
      "Epoch 145/400\n",
      "1000/1000 [==============================] - 1s 822us/sample - loss: 0.4885 - accuracy: 0.6923\n",
      "Epoch 146/400\n",
      "1000/1000 [==============================] - 1s 815us/sample - loss: 0.5104 - accuracy: 0.6756\n",
      "Epoch 147/400\n",
      "1000/1000 [==============================] - 1s 819us/sample - loss: 0.5076 - accuracy: 0.6801\n",
      "Epoch 148/400\n",
      "1000/1000 [==============================] - 1s 825us/sample - loss: 0.4837 - accuracy: 0.6969\n",
      "Epoch 149/400\n",
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.4798 - accuracy: 0.7012\n",
      "Epoch 150/400\n",
      "1000/1000 [==============================] - 1s 781us/sample - loss: 0.4730 - accuracy: 0.7001\n",
      "Epoch 151/400\n",
      "1000/1000 [==============================] - 1s 789us/sample - loss: 0.4694 - accuracy: 0.7102\n",
      "Epoch 152/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.4758 - accuracy: 0.7022\n",
      "Epoch 153/400\n",
      "1000/1000 [==============================] - 1s 778us/sample - loss: 0.4874 - accuracy: 0.6966\n",
      "Epoch 154/400\n",
      "1000/1000 [==============================] - 1s 791us/sample - loss: 0.4732 - accuracy: 0.7068\n",
      "Epoch 155/400\n",
      "1000/1000 [==============================] - 1s 741us/sample - loss: 0.4960 - accuracy: 0.6941\n",
      "Epoch 156/400\n",
      "1000/1000 [==============================] - 1s 759us/sample - loss: 0.5273 - accuracy: 0.6705\n",
      "Epoch 157/400\n",
      "1000/1000 [==============================] - 1s 787us/sample - loss: 0.4712 - accuracy: 0.7085\n",
      "Epoch 158/400\n",
      "1000/1000 [==============================] - 1s 807us/sample - loss: 0.4659 - accuracy: 0.7129\n",
      "Epoch 159/400\n",
      "1000/1000 [==============================] - 1s 789us/sample - loss: 0.4645 - accuracy: 0.7116\n",
      "Epoch 160/400\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.4600 - accuracy: 0.7144\n",
      "Epoch 161/400\n",
      "1000/1000 [==============================] - 1s 814us/sample - loss: 0.4814 - accuracy: 0.6952\n",
      "Epoch 162/400\n",
      "1000/1000 [==============================] - 1s 786us/sample - loss: 0.4770 - accuracy: 0.7034\n",
      "Epoch 163/400\n",
      "1000/1000 [==============================] - 1s 777us/sample - loss: 0.4622 - accuracy: 0.7085\n",
      "Epoch 164/400\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.4607 - accuracy: 0.7159\n",
      "Epoch 165/400\n",
      "1000/1000 [==============================] - 1s 756us/sample - loss: 0.4854 - accuracy: 0.7004\n",
      "Epoch 166/400\n",
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.4628 - accuracy: 0.7146\n",
      "Epoch 167/400\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.4565 - accuracy: 0.7204\n",
      "Epoch 168/400\n",
      "1000/1000 [==============================] - 1s 776us/sample - loss: 0.4577 - accuracy: 0.7139\n",
      "Epoch 169/400\n",
      "1000/1000 [==============================] - 1s 778us/sample - loss: 0.4675 - accuracy: 0.7078\n",
      "Epoch 170/400\n",
      "1000/1000 [==============================] - 1s 796us/sample - loss: 0.4691 - accuracy: 0.7054\n",
      "Epoch 171/400\n",
      "1000/1000 [==============================] - 1s 792us/sample - loss: 0.4552 - accuracy: 0.7181\n",
      "Epoch 172/400\n",
      "1000/1000 [==============================] - 1s 800us/sample - loss: 0.4590 - accuracy: 0.7173\n",
      "Epoch 173/400\n",
      "1000/1000 [==============================] - 1s 798us/sample - loss: 0.4511 - accuracy: 0.7241\n",
      "Epoch 174/400\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.4827 - accuracy: 0.7039\n",
      "Epoch 175/400\n",
      "1000/1000 [==============================] - 1s 786us/sample - loss: 0.4954 - accuracy: 0.6908\n",
      "Epoch 176/400\n",
      "1000/1000 [==============================] - 1s 791us/sample - loss: 0.5145 - accuracy: 0.6851\n",
      "Epoch 177/400\n",
      "1000/1000 [==============================] - 1s 791us/sample - loss: 0.4637 - accuracy: 0.7108\n",
      "Epoch 178/400\n",
      "1000/1000 [==============================] - 1s 747us/sample - loss: 0.4443 - accuracy: 0.7297\n",
      "Epoch 179/400\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.4740 - accuracy: 0.7098\n",
      "Epoch 180/400\n",
      "1000/1000 [==============================] - 1s 787us/sample - loss: 0.4764 - accuracy: 0.7052\n",
      "Epoch 181/400\n",
      "1000/1000 [==============================] - 1s 794us/sample - loss: 0.4532 - accuracy: 0.7196\n",
      "Epoch 182/400\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.4681 - accuracy: 0.7163\n",
      "Epoch 183/400\n",
      "1000/1000 [==============================] - 1s 745us/sample - loss: 0.4901 - accuracy: 0.6971\n",
      "Epoch 184/400\n",
      "1000/1000 [==============================] - 1s 762us/sample - loss: 0.4563 - accuracy: 0.7239\n",
      "Epoch 185/400\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.4638 - accuracy: 0.7199\n",
      "Epoch 186/400\n",
      "1000/1000 [==============================] - 1s 803us/sample - loss: 0.4420 - accuracy: 0.7294\n",
      "Epoch 187/400\n",
      "1000/1000 [==============================] - 1s 795us/sample - loss: 0.4363 - accuracy: 0.7351\n",
      "Epoch 188/400\n",
      "1000/1000 [==============================] - 1s 771us/sample - loss: 0.4425 - accuracy: 0.7276\n",
      "Epoch 189/400\n",
      "1000/1000 [==============================] - 1s 793us/sample - loss: 0.4393 - accuracy: 0.7316\n",
      "Epoch 190/400\n",
      "1000/1000 [==============================] - 1s 796us/sample - loss: 0.4480 - accuracy: 0.7262\n",
      "Epoch 191/400\n",
      "1000/1000 [==============================] - 1s 832us/sample - loss: 0.4365 - accuracy: 0.7343\n",
      "Epoch 192/400\n",
      "1000/1000 [==============================] - 1s 788us/sample - loss: 0.4335 - accuracy: 0.7336\n",
      "Epoch 193/400\n",
      "1000/1000 [==============================] - 1s 788us/sample - loss: 0.4346 - accuracy: 0.7345\n",
      "Epoch 194/400\n",
      "1000/1000 [==============================] - 1s 792us/sample - loss: 0.4282 - accuracy: 0.7378\n",
      "Epoch 195/400\n",
      "1000/1000 [==============================] - 1s 795us/sample - loss: 0.4269 - accuracy: 0.7405\n",
      "Epoch 196/400\n",
      "1000/1000 [==============================] - 1s 779us/sample - loss: 0.4281 - accuracy: 0.7365\n",
      "Epoch 197/400\n",
      "1000/1000 [==============================] - 1s 774us/sample - loss: 0.4406 - accuracy: 0.7267\n",
      "Epoch 198/400\n",
      "1000/1000 [==============================] - 1s 856us/sample - loss: 0.4358 - accuracy: 0.7334\n",
      "Epoch 199/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4330 - accuracy: 0.7385\n",
      "Epoch 200/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4253 - accuracy: 0.7397\n",
      "Epoch 201/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4213 - accuracy: 0.7460\n",
      "Epoch 202/400\n",
      "1000/1000 [==============================] - 1s 928us/sample - loss: 0.4202 - accuracy: 0.7419\n",
      "Epoch 203/400\n",
      "1000/1000 [==============================] - 1s 863us/sample - loss: 0.4191 - accuracy: 0.7396\n",
      "Epoch 204/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4232 - accuracy: 0.7369\n",
      "Epoch 205/400\n",
      "1000/1000 [==============================] - 1s 926us/sample - loss: 0.4198 - accuracy: 0.7440\n",
      "Epoch 206/400\n",
      "1000/1000 [==============================] - 1s 948us/sample - loss: 0.4209 - accuracy: 0.7428\n",
      "Epoch 207/400\n",
      "1000/1000 [==============================] - 1s 847us/sample - loss: 0.4233 - accuracy: 0.7371\n",
      "Epoch 208/400\n",
      "1000/1000 [==============================] - 1s 932us/sample - loss: 0.5019 - accuracy: 0.6986\n",
      "Epoch 209/400\n",
      "1000/1000 [==============================] - 1s 864us/sample - loss: 0.4765 - accuracy: 0.7072\n",
      "Epoch 210/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4230 - accuracy: 0.7422\n",
      "Epoch 211/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4192 - accuracy: 0.7446\n",
      "Epoch 212/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4143 - accuracy: 0.7440\n",
      "Epoch 213/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4793 - accuracy: 0.7042\n",
      "Epoch 214/400\n",
      "1000/1000 [==============================] - 1s 972us/sample - loss: 0.4509 - accuracy: 0.7271\n",
      "Epoch 215/400\n",
      "1000/1000 [==============================] - 1s 915us/sample - loss: 0.4393 - accuracy: 0.7249\n",
      "Epoch 216/400\n",
      "1000/1000 [==============================] - 1s 844us/sample - loss: 0.4421 - accuracy: 0.7257\n",
      "Epoch 217/400\n",
      "1000/1000 [==============================] - 1s 902us/sample - loss: 0.4195 - accuracy: 0.7402\n",
      "Epoch 218/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4092 - accuracy: 0.7479\n",
      "Epoch 219/400\n",
      "1000/1000 [==============================] - 1s 969us/sample - loss: 0.4079 - accuracy: 0.7468\n",
      "Epoch 220/400\n",
      "1000/1000 [==============================] - 1s 917us/sample - loss: 0.4079 - accuracy: 0.7464\n",
      "Epoch 221/400\n",
      "1000/1000 [==============================] - 1s 850us/sample - loss: 0.4062 - accuracy: 0.7522\n",
      "Epoch 222/400\n",
      "1000/1000 [==============================] - 1s 754us/sample - loss: 0.4051 - accuracy: 0.7462\n",
      "Epoch 223/400\n",
      "1000/1000 [==============================] - 1s 755us/sample - loss: 0.4046 - accuracy: 0.7466\n",
      "Epoch 224/400\n",
      "1000/1000 [==============================] - 1s 873us/sample - loss: 0.4077 - accuracy: 0.7485\n",
      "Epoch 225/400\n",
      "1000/1000 [==============================] - 1s 903us/sample - loss: 0.4289 - accuracy: 0.7344\n",
      "Epoch 226/400\n",
      "1000/1000 [==============================] - 1s 902us/sample - loss: 0.4067 - accuracy: 0.7492\n",
      "Epoch 227/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 912us/sample - loss: 0.4028 - accuracy: 0.7511\n",
      "Epoch 228/400\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.3999 - accuracy: 0.7550\n",
      "Epoch 229/400\n",
      "1000/1000 [==============================] - 1s 775us/sample - loss: 0.4045 - accuracy: 0.7513\n",
      "Epoch 230/400\n",
      "1000/1000 [==============================] - 1s 752us/sample - loss: 0.4672 - accuracy: 0.7171\n",
      "Epoch 231/400\n",
      "1000/1000 [==============================] - 1s 837us/sample - loss: 0.5218 - accuracy: 0.6941\n",
      "Epoch 232/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4392 - accuracy: 0.7304\n",
      "Epoch 233/400\n",
      "1000/1000 [==============================] - 1s 766us/sample - loss: 0.4072 - accuracy: 0.7531\n",
      "Epoch 234/400\n",
      "1000/1000 [==============================] - 1s 821us/sample - loss: 0.4069 - accuracy: 0.7503\n",
      "Epoch 235/400\n",
      "1000/1000 [==============================] - 1s 943us/sample - loss: 0.4033 - accuracy: 0.7507\n",
      "Epoch 236/400\n",
      "1000/1000 [==============================] - 1s 831us/sample - loss: 0.3947 - accuracy: 0.7576\n",
      "Epoch 237/400\n",
      "1000/1000 [==============================] - 1s 829us/sample - loss: 0.3941 - accuracy: 0.7602\n",
      "Epoch 238/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3926 - accuracy: 0.7592\n",
      "Epoch 239/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3899 - accuracy: 0.7615\n",
      "Epoch 240/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3920 - accuracy: 0.7615\n",
      "Epoch 241/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3897 - accuracy: 0.7579\n",
      "Epoch 242/400\n",
      "1000/1000 [==============================] - 1s 916us/sample - loss: 0.3898 - accuracy: 0.7629\n",
      "Epoch 243/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3890 - accuracy: 0.7623\n",
      "Epoch 244/400\n",
      "1000/1000 [==============================] - 1s 851us/sample - loss: 0.4222 - accuracy: 0.7418\n",
      "Epoch 245/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4306 - accuracy: 0.7387\n",
      "Epoch 246/400\n",
      "1000/1000 [==============================] - 1s 853us/sample - loss: 0.3933 - accuracy: 0.7609\n",
      "Epoch 247/400\n",
      "1000/1000 [==============================] - 1s 853us/sample - loss: 0.3879 - accuracy: 0.7638\n",
      "Epoch 248/400\n",
      "1000/1000 [==============================] - 1s 880us/sample - loss: 0.3851 - accuracy: 0.7633\n",
      "Epoch 249/400\n",
      "1000/1000 [==============================] - 1s 840us/sample - loss: 0.3909 - accuracy: 0.7663\n",
      "Epoch 250/400\n",
      "1000/1000 [==============================] - 1s 761us/sample - loss: 0.3848 - accuracy: 0.7648\n",
      "Epoch 251/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4177 - accuracy: 0.7513\n",
      "Epoch 252/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4630 - accuracy: 0.7231\n",
      "Epoch 253/400\n",
      "1000/1000 [==============================] - 1s 989us/sample - loss: 0.4591 - accuracy: 0.7243\n",
      "Epoch 254/400\n",
      "1000/1000 [==============================] - 1s 749us/sample - loss: 0.3973 - accuracy: 0.7555\n",
      "Epoch 255/400\n",
      "1000/1000 [==============================] - 1s 944us/sample - loss: 0.3842 - accuracy: 0.7659\n",
      "Epoch 256/400\n",
      "1000/1000 [==============================] - 1s 777us/sample - loss: 0.3816 - accuracy: 0.7657\n",
      "Epoch 257/400\n",
      "1000/1000 [==============================] - 1s 783us/sample - loss: 0.3767 - accuracy: 0.7747\n",
      "Epoch 258/400\n",
      "1000/1000 [==============================] - 1s 774us/sample - loss: 0.3766 - accuracy: 0.7734\n",
      "Epoch 259/400\n",
      "1000/1000 [==============================] - 1s 777us/sample - loss: 0.3767 - accuracy: 0.7752\n",
      "Epoch 260/400\n",
      "1000/1000 [==============================] - 1s 777us/sample - loss: 0.3788 - accuracy: 0.7741\n",
      "Epoch 261/400\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.3771 - accuracy: 0.7728\n",
      "Epoch 262/400\n",
      "1000/1000 [==============================] - 1s 797us/sample - loss: 0.3776 - accuracy: 0.7699\n",
      "Epoch 263/400\n",
      "1000/1000 [==============================] - 1s 773us/sample - loss: 0.3740 - accuracy: 0.7708\n",
      "Epoch 264/400\n",
      "1000/1000 [==============================] - 1s 754us/sample - loss: 0.3733 - accuracy: 0.7758\n",
      "Epoch 265/400\n",
      "1000/1000 [==============================] - 1s 843us/sample - loss: 0.3787 - accuracy: 0.7729\n",
      "Epoch 266/400\n",
      "1000/1000 [==============================] - 1s 938us/sample - loss: 0.3724 - accuracy: 0.7743\n",
      "Epoch 267/400\n",
      "1000/1000 [==============================] - 1s 777us/sample - loss: 0.3732 - accuracy: 0.7702\n",
      "Epoch 268/400\n",
      "1000/1000 [==============================] - 1s 947us/sample - loss: 0.3708 - accuracy: 0.7783\n",
      "Epoch 269/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3739 - accuracy: 0.7743\n",
      "Epoch 270/400\n",
      "1000/1000 [==============================] - 1s 825us/sample - loss: 0.4070 - accuracy: 0.7573\n",
      "Epoch 271/400\n",
      "1000/1000 [==============================] - 1s 809us/sample - loss: 0.4856 - accuracy: 0.7187\n",
      "Epoch 272/400\n",
      "1000/1000 [==============================] - 1s 863us/sample - loss: 0.4471 - accuracy: 0.7341\n",
      "Epoch 273/400\n",
      "1000/1000 [==============================] - 1s 822us/sample - loss: 0.4001 - accuracy: 0.7603\n",
      "Epoch 274/400\n",
      "1000/1000 [==============================] - 1s 845us/sample - loss: 0.3764 - accuracy: 0.7764\n",
      "Epoch 275/400\n",
      "1000/1000 [==============================] - 1s 889us/sample - loss: 0.3677 - accuracy: 0.7794\n",
      "Epoch 276/400\n",
      "1000/1000 [==============================] - 1s 858us/sample - loss: 0.3649 - accuracy: 0.7807\n",
      "Epoch 277/400\n",
      "1000/1000 [==============================] - 1s 880us/sample - loss: 0.3660 - accuracy: 0.7782\n",
      "Epoch 278/400\n",
      "1000/1000 [==============================] - 1s 805us/sample - loss: 0.3661 - accuracy: 0.7802\n",
      "Epoch 279/400\n",
      "1000/1000 [==============================] - 1s 865us/sample - loss: 0.3616 - accuracy: 0.7883\n",
      "Epoch 280/400\n",
      "1000/1000 [==============================] - 1s 858us/sample - loss: 0.3646 - accuracy: 0.7821\n",
      "Epoch 281/400\n",
      "1000/1000 [==============================] - 1s 880us/sample - loss: 0.3719 - accuracy: 0.7804\n",
      "Epoch 282/400\n",
      "1000/1000 [==============================] - 1s 924us/sample - loss: 0.3593 - accuracy: 0.7883\n",
      "Epoch 283/400\n",
      "1000/1000 [==============================] - 1s 778us/sample - loss: 0.3691 - accuracy: 0.7826\n",
      "Epoch 284/400\n",
      "1000/1000 [==============================] - 1s 742us/sample - loss: 0.3740 - accuracy: 0.7767\n",
      "Epoch 285/400\n",
      "1000/1000 [==============================] - 1s 844us/sample - loss: 0.3613 - accuracy: 0.7864\n",
      "Epoch 286/400\n",
      "1000/1000 [==============================] - 1s 772us/sample - loss: 0.3667 - accuracy: 0.7853\n",
      "Epoch 287/400\n",
      "1000/1000 [==============================] - 1s 833us/sample - loss: 0.3609 - accuracy: 0.7869\n",
      "Epoch 288/400\n",
      "1000/1000 [==============================] - 1s 955us/sample - loss: 0.3601 - accuracy: 0.7898\n",
      "Epoch 289/400\n",
      "1000/1000 [==============================] - 1s 949us/sample - loss: 0.3945 - accuracy: 0.7700\n",
      "Epoch 290/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3687 - accuracy: 0.7811\n",
      "Epoch 291/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3572 - accuracy: 0.7904\n",
      "Epoch 292/400\n",
      "1000/1000 [==============================] - 1s 927us/sample - loss: 0.3530 - accuracy: 0.7905\n",
      "Epoch 293/400\n",
      "1000/1000 [==============================] - 1s 921us/sample - loss: 0.3521 - accuracy: 0.7937\n",
      "Epoch 294/400\n",
      "1000/1000 [==============================] - 1s 936us/sample - loss: 0.3508 - accuracy: 0.7916\n",
      "Epoch 295/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3470 - accuracy: 0.7955\n",
      "Epoch 296/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3575 - accuracy: 0.7881\n",
      "Epoch 297/400\n",
      "1000/1000 [==============================] - 1s 910us/sample - loss: 0.3554 - accuracy: 0.7890\n",
      "Epoch 298/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3513 - accuracy: 0.7935\n",
      "Epoch 299/400\n",
      "1000/1000 [==============================] - 1s 758us/sample - loss: 0.3591 - accuracy: 0.7857\n",
      "Epoch 300/400\n",
      "1000/1000 [==============================] - 1s 830us/sample - loss: 0.3509 - accuracy: 0.7966\n",
      "Epoch 301/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3554 - accuracy: 0.7889\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3515 - accuracy: 0.7923\n",
      "Epoch 303/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3459 - accuracy: 0.7981\n",
      "Epoch 304/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4170 - accuracy: 0.7684\n",
      "Epoch 305/400\n",
      "1000/1000 [==============================] - 1s 881us/sample - loss: 0.4199 - accuracy: 0.7570\n",
      "Epoch 306/400\n",
      "1000/1000 [==============================] - 1s 810us/sample - loss: 0.3737 - accuracy: 0.7822\n",
      "Epoch 307/400\n",
      "1000/1000 [==============================] - 1s 806us/sample - loss: 0.3520 - accuracy: 0.7926\n",
      "Epoch 308/400\n",
      "1000/1000 [==============================] - 1s 743us/sample - loss: 0.3443 - accuracy: 0.7974\n",
      "Epoch 309/400\n",
      "1000/1000 [==============================] - 1s 755us/sample - loss: 0.3418 - accuracy: 0.8015\n",
      "Epoch 310/400\n",
      "1000/1000 [==============================] - 1s 747us/sample - loss: 0.3421 - accuracy: 0.8019\n",
      "Epoch 311/400\n",
      "1000/1000 [==============================] - 1s 750us/sample - loss: 0.3416 - accuracy: 0.8043\n",
      "Epoch 312/400\n",
      "1000/1000 [==============================] - 1s 739us/sample - loss: 0.3370 - accuracy: 0.8099\n",
      "Epoch 313/400\n",
      "1000/1000 [==============================] - 1s 731us/sample - loss: 0.3449 - accuracy: 0.8032\n",
      "Epoch 314/400\n",
      "1000/1000 [==============================] - 1s 846us/sample - loss: 0.3744 - accuracy: 0.7871\n",
      "Epoch 315/400\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.4232 - accuracy: 0.7577\n",
      "Epoch 316/400\n",
      "1000/1000 [==============================] - 1s 819us/sample - loss: 0.4287 - accuracy: 0.7526\n",
      "Epoch 317/400\n",
      "1000/1000 [==============================] - 1s 769us/sample - loss: 0.3556 - accuracy: 0.7929\n",
      "Epoch 318/400\n",
      "1000/1000 [==============================] - 1s 887us/sample - loss: 0.3407 - accuracy: 0.7980\n",
      "Epoch 319/400\n",
      "1000/1000 [==============================] - 1s 760us/sample - loss: 0.3402 - accuracy: 0.8003\n",
      "Epoch 320/400\n",
      "1000/1000 [==============================] - 1s 768us/sample - loss: 0.3357 - accuracy: 0.8074\n",
      "Epoch 321/400\n",
      "1000/1000 [==============================] - 1s 751us/sample - loss: 0.3399 - accuracy: 0.8039\n",
      "Epoch 322/400\n",
      "1000/1000 [==============================] - 1s 837us/sample - loss: 0.3559 - accuracy: 0.7946\n",
      "Epoch 323/400\n",
      "1000/1000 [==============================] - 1s 753us/sample - loss: 0.3938 - accuracy: 0.7759\n",
      "Epoch 324/400\n",
      "1000/1000 [==============================] - 1s 942us/sample - loss: 0.3563 - accuracy: 0.7917\n",
      "Epoch 325/400\n",
      "1000/1000 [==============================] - 1s 993us/sample - loss: 0.3521 - accuracy: 0.7945\n",
      "Epoch 326/400\n",
      "1000/1000 [==============================] - 1s 826us/sample - loss: 0.3319 - accuracy: 0.8087\n",
      "Epoch 327/400\n",
      "1000/1000 [==============================] - 1s 818us/sample - loss: 0.3307 - accuracy: 0.8117\n",
      "Epoch 328/400\n",
      "1000/1000 [==============================] - 1s 949us/sample - loss: 0.3289 - accuracy: 0.8126\n",
      "Epoch 329/400\n",
      "1000/1000 [==============================] - 1s 839us/sample - loss: 0.3294 - accuracy: 0.8137\n",
      "Epoch 330/400\n",
      "1000/1000 [==============================] - 1s 891us/sample - loss: 0.3343 - accuracy: 0.8097\n",
      "Epoch 331/400\n",
      "1000/1000 [==============================] - 1s 942us/sample - loss: 0.3295 - accuracy: 0.8133\n",
      "Epoch 332/400\n",
      "1000/1000 [==============================] - 1s 921us/sample - loss: 0.3294 - accuracy: 0.8090\n",
      "Epoch 333/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3276 - accuracy: 0.8130\n",
      "Epoch 334/400\n",
      "1000/1000 [==============================] - 1s 745us/sample - loss: 0.3247 - accuracy: 0.8164\n",
      "Epoch 335/400\n",
      "1000/1000 [==============================] - 1s 766us/sample - loss: 0.3239 - accuracy: 0.8165\n",
      "Epoch 336/400\n",
      "1000/1000 [==============================] - 1s 770us/sample - loss: 0.3560 - accuracy: 0.8003\n",
      "Epoch 337/400\n",
      "1000/1000 [==============================] - 1s 779us/sample - loss: 0.5613 - accuracy: 0.7092\n",
      "Epoch 338/400\n",
      "1000/1000 [==============================] - 1s 841us/sample - loss: 0.3900 - accuracy: 0.7728\n",
      "Epoch 339/400\n",
      "1000/1000 [==============================] - 1s 757us/sample - loss: 0.3404 - accuracy: 0.8085\n",
      "Epoch 340/400\n",
      "1000/1000 [==============================] - 1s 770us/sample - loss: 0.3357 - accuracy: 0.8106\n",
      "Epoch 341/400\n",
      "1000/1000 [==============================] - 1s 766us/sample - loss: 0.3412 - accuracy: 0.8057\n",
      "Epoch 342/400\n",
      "1000/1000 [==============================] - 1s 767us/sample - loss: 0.3256 - accuracy: 0.8175\n",
      "Epoch 343/400\n",
      "1000/1000 [==============================] - 1s 771us/sample - loss: 0.3201 - accuracy: 0.8216\n",
      "Epoch 344/400\n",
      "1000/1000 [==============================] - 1s 758us/sample - loss: 0.3201 - accuracy: 0.8211\n",
      "Epoch 345/400\n",
      "1000/1000 [==============================] - 1s 728us/sample - loss: 0.3200 - accuracy: 0.8172\n",
      "Epoch 346/400\n",
      "1000/1000 [==============================] - 1s 768us/sample - loss: 0.3199 - accuracy: 0.8228\n",
      "Epoch 347/400\n",
      "1000/1000 [==============================] - 1s 849us/sample - loss: 0.3194 - accuracy: 0.8214\n",
      "Epoch 348/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3174 - accuracy: 0.8246\n",
      "Epoch 349/400\n",
      "1000/1000 [==============================] - 1s 887us/sample - loss: 0.3179 - accuracy: 0.8208\n",
      "Epoch 350/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3242 - accuracy: 0.82020s - loss: 0.3267 - ac\n",
      "Epoch 351/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3191 - accuracy: 0.8209\n",
      "Epoch 352/400\n",
      "1000/1000 [==============================] - 1s 936us/sample - loss: 0.3211 - accuracy: 0.8218\n",
      "Epoch 353/400\n",
      "1000/1000 [==============================] - 1s 911us/sample - loss: 0.3228 - accuracy: 0.8237\n",
      "Epoch 354/400\n",
      "1000/1000 [==============================] - 1s 937us/sample - loss: 0.3185 - accuracy: 0.8183\n",
      "Epoch 355/400\n",
      "1000/1000 [==============================] - 1s 913us/sample - loss: 0.3195 - accuracy: 0.8223\n",
      "Epoch 356/400\n",
      "1000/1000 [==============================] - 1s 916us/sample - loss: 0.3142 - accuracy: 0.8272\n",
      "Epoch 357/400\n",
      "1000/1000 [==============================] - 1s 916us/sample - loss: 0.3144 - accuracy: 0.8231\n",
      "Epoch 358/400\n",
      "1000/1000 [==============================] - 1s 913us/sample - loss: 0.3166 - accuracy: 0.8211\n",
      "Epoch 359/400\n",
      "1000/1000 [==============================] - 1s 927us/sample - loss: 0.3273 - accuracy: 0.8161\n",
      "Epoch 360/400\n",
      "1000/1000 [==============================] - 1s 958us/sample - loss: 0.3185 - accuracy: 0.8224\n",
      "Epoch 361/400\n",
      "1000/1000 [==============================] - 1s 907us/sample - loss: 0.3152 - accuracy: 0.8253\n",
      "Epoch 362/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3120 - accuracy: 0.8269\n",
      "Epoch 363/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3198 - accuracy: 0.8193\n",
      "Epoch 364/400\n",
      "1000/1000 [==============================] - 1s 915us/sample - loss: 0.4168 - accuracy: 0.7838\n",
      "Epoch 365/400\n",
      "1000/1000 [==============================] - 1s 781us/sample - loss: 0.4288 - accuracy: 0.7674\n",
      "Epoch 366/400\n",
      "1000/1000 [==============================] - 1s 788us/sample - loss: 0.3464 - accuracy: 0.8047\n",
      "Epoch 367/400\n",
      "1000/1000 [==============================] - 1s 825us/sample - loss: 0.3137 - accuracy: 0.8286\n",
      "Epoch 368/400\n",
      "1000/1000 [==============================] - 1s 842us/sample - loss: 0.3095 - accuracy: 0.8301\n",
      "Epoch 369/400\n",
      "1000/1000 [==============================] - 1s 929us/sample - loss: 0.3053 - accuracy: 0.8309\n",
      "Epoch 370/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3025 - accuracy: 0.8367\n",
      "Epoch 371/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3031 - accuracy: 0.8361\n",
      "Epoch 372/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3051 - accuracy: 0.8327\n",
      "Epoch 373/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3045 - accuracy: 0.8329\n",
      "Epoch 374/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3026 - accuracy: 0.8323\n",
      "Epoch 375/400\n",
      "1000/1000 [==============================] - 1s 859us/sample - loss: 0.3003 - accuracy: 0.8344\n",
      "Epoch 376/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3000 - accuracy: 0.8379\n",
      "Epoch 377/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3110 - accuracy: 0.8312\n",
      "Epoch 378/400\n",
      "1000/1000 [==============================] - 1s 794us/sample - loss: 0.3037 - accuracy: 0.8314\n",
      "Epoch 379/400\n",
      "1000/1000 [==============================] - 1s 708us/sample - loss: 0.2982 - accuracy: 0.8374\n",
      "Epoch 380/400\n",
      "1000/1000 [==============================] - 1s 863us/sample - loss: 0.2992 - accuracy: 0.8353\n",
      "Epoch 381/400\n",
      "1000/1000 [==============================] - 1s 760us/sample - loss: 0.3043 - accuracy: 0.8341\n",
      "Epoch 382/400\n",
      "1000/1000 [==============================] - 1s 778us/sample - loss: 0.3001 - accuracy: 0.8359\n",
      "Epoch 383/400\n",
      "1000/1000 [==============================] - 1s 968us/sample - loss: 0.3013 - accuracy: 0.8345\n",
      "Epoch 384/400\n",
      "1000/1000 [==============================] - 1s 879us/sample - loss: 0.3117 - accuracy: 0.8319\n",
      "Epoch 385/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3342 - accuracy: 0.8189\n",
      "Epoch 386/400\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.4055 - accuracy: 0.7810\n",
      "Epoch 387/400\n",
      "1000/1000 [==============================] - 1s 883us/sample - loss: 0.3516 - accuracy: 0.8116\n",
      "Epoch 388/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3060 - accuracy: 0.8288\n",
      "Epoch 389/400\n",
      "1000/1000 [==============================] - 1s 996us/sample - loss: 0.3023 - accuracy: 0.8324\n",
      "Epoch 390/400\n",
      "1000/1000 [==============================] - 1s 896us/sample - loss: 0.3023 - accuracy: 0.8336\n",
      "Epoch 391/400\n",
      "1000/1000 [==============================] - 1s 895us/sample - loss: 0.3005 - accuracy: 0.8373\n",
      "Epoch 392/400\n",
      "1000/1000 [==============================] - 1s 855us/sample - loss: 0.2887 - accuracy: 0.8444\n",
      "Epoch 393/400\n",
      "1000/1000 [==============================] - 1s 963us/sample - loss: 0.2893 - accuracy: 0.8435\n",
      "Epoch 394/400\n",
      "1000/1000 [==============================] - 1s 928us/sample - loss: 0.2887 - accuracy: 0.8431\n",
      "Epoch 395/400\n",
      "1000/1000 [==============================] - 1s 911us/sample - loss: 0.3085 - accuracy: 0.8315\n",
      "Epoch 396/400\n",
      "1000/1000 [==============================] - 1s 919us/sample - loss: 0.3010 - accuracy: 0.8338\n",
      "Epoch 397/400\n",
      "1000/1000 [==============================] - 1s 918us/sample - loss: 0.2892 - accuracy: 0.8406\n",
      "Epoch 398/400\n",
      "1000/1000 [==============================] - 1s 929us/sample - loss: 0.2882 - accuracy: 0.8489\n",
      "Epoch 399/400\n",
      "1000/1000 [==============================] - 1s 878us/sample - loss: 0.2882 - accuracy: 0.8425\n",
      "Epoch 400/400\n",
      "1000/1000 [==============================] - 1s 872us/sample - loss: 0.2869 - accuracy: 0.8478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1345706d8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train LSTM\n",
    "model.fit(X_train, y_train, epochs=n_epoch, batch_size=n_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation Performance in MSE : 0.618643\n",
      "Show some specific examples\n",
      "Input =8.15625+2.34375, Expected=10.5, Predicted=10.4375\n",
      "Input =8.40625+4.4375, Expected=12.84375, Predicted=12.625\n",
      "Input =11.0625+9.125, Expected=20.1875, Predicted=20.5\n",
      "Input =7.15625+2.40625, Expected=9.5625, Predicted=9.5\n",
      "Input =9.4375+6.15625, Expected=15.59375, Predicted=15.5\n",
      "Input =9.03125+12.375, Expected=21.40625, Predicted=20.5\n",
      "Input =3.46875+6.40625, Expected=9.875, Predicted=8.96875\n",
      "Input =9.28125+11.46875, Expected=20.75, Predicted=20.5625\n",
      "Input =7.09375+12.5, Expected=19.59375, Predicted=19.0\n",
      "Input =12.3125+5.3125, Expected=17.625, Predicted=16.59375\n",
      "Input =1.4375+4.09375, Expected=5.53125, Predicted=5.125\n",
      "Input =15.46875+7.28125, Expected=22.75, Predicted=21.96875\n",
      "Input =9.46875+7.28125, Expected=16.75, Predicted=16.96875\n",
      "Input =16.09375+5.1875, Expected=21.28125, Predicted=22.46875\n",
      "Input =8.34375+9.15625, Expected=17.5, Predicted=17.46875\n",
      "Input =3.15625+5.4375, Expected=8.59375, Predicted=8.84375\n",
      "Input =1.15625+5.03125, Expected=6.1875, Predicted=6.3125\n",
      "Input =11.21875+11.46875, Expected=22.6875, Predicted=22.46875\n",
      "Input =11.5+3.25, Expected=14.75, Predicted=14.75\n",
      "Input =8.46875+3.3125, Expected=11.78125, Predicted=11.78125\n",
      "Input =8.40625+2.3125, Expected=10.71875, Predicted=10.5\n",
      "Input =13.125+14.03125, Expected=27.15625, Predicted=27.0\n",
      "Input =10.03125+9.0625, Expected=19.09375, Predicted=18.46875\n",
      "Input =9.21875+13.40625, Expected=22.625, Predicted=22.84375\n",
      "Input =14.25+12.25, Expected=26.5, Predicted=26.5\n",
      "Input =3.03125+4.34375, Expected=7.375, Predicted=7.125\n",
      "Input =7.21875+6.46875, Expected=13.6875, Predicted=13.625\n",
      "Input =12.3125+14.375, Expected=26.6875, Predicted=27.40625\n",
      "Input =14.03125+14.0625, Expected=28.09375, Predicted=28.375\n",
      "Input =4.40625+16.46875, Expected=20.875, Predicted=21.3125\n",
      "Input =1.09375+2.34375, Expected=3.4375, Predicted=1.5\n",
      "Input =5.34375+6.5, Expected=11.84375, Predicted=11.59375\n",
      "Input =2.34375+7.125, Expected=9.46875, Predicted=9.96875\n",
      "Input =5.25+12.1875, Expected=17.4375, Predicted=17.21875\n",
      "Input =3.46875+13.375, Expected=16.84375, Predicted=16.96875\n",
      "Input =11.3125+10.46875, Expected=21.78125, Predicted=23.96875\n",
      "Input =5.21875+9.34375, Expected=14.5625, Predicted=14.71875\n",
      "Input =11.34375+9.09375, Expected=20.4375, Predicted=23.71875\n",
      "Input =8.0625+3.0625, Expected=11.125, Predicted=11.125\n",
      "Input =14.40625+10.0625, Expected=24.46875, Predicted=24.84375\n",
      "Input =10.5+14.34375, Expected=24.84375, Predicted=24.46875\n",
      "Input =16.5+16.125, Expected=0.625, Predicted=0.0\n",
      "Input =16.25+3.375, Expected=19.625, Predicted=19.5\n",
      "Input =9.15625+13.28125, Expected=22.4375, Predicted=22.84375\n",
      "Input =3.40625+14.28125, Expected=17.6875, Predicted=17.71875\n",
      "Input =9.5+9.21875, Expected=18.71875, Predicted=19.59375\n",
      "Input =12.34375+12.09375, Expected=24.4375, Predicted=24.46875\n",
      "Input =6.5+11.03125, Expected=17.53125, Predicted=17.71875\n",
      "Input =11.34375+10.40625, Expected=21.75, Predicted=22.96875\n",
      "Input =3.21875+11.46875, Expected=14.6875, Predicted=14.5\n"
     ]
    }
   ],
   "source": [
    "#evaluate on some new patterns\n",
    "n_samples = 100\n",
    "X_test, y_test = generate_data(n_samples, n_numbers, largest, alphabet)\n",
    "# convert input to float32 to match the ops datatype\n",
    "X_test = X_test.astype(np.float32)\n",
    "pred = model.predict(X_test, batch_size=n_batch, verbose=0)\n",
    "# calculate error\n",
    "X_test_invert = [invert(x, alphabet) for x in X_test]\n",
    "expected = [float(invert(x, alphabet)) for x in y_test]\n",
    "predicted = [float(invert(x, alphabet)) for x in pred]\n",
    "mse = ((np.array(expected) - np.array(predicted))**2).mean(axis=0)\n",
    "print(\"Calculation Performance in MSE : %.6f\" % mse)\n",
    "print(\"Show some specific examples\")\n",
    "for i in range(50):\n",
    "    print('Input =%s, Expected=%s, Predicted=%s' % (X_test_invert[i], expected[i], predicted[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Re-do Task 2 by replacing all LSTM layers with GRU (just search tensorflow.keras.GRU on google)\n",
    "# and summarize your observations in prediction performance and computation efficiency.\n",
    "# Must use the same optimizer, learning rate, and number of training epochs as used in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 64)                13440     \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 10, 32)            9408      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 10, 4)             132       \n",
      "=================================================================\n",
      "Total params: 22,980\n",
      "Trainable params: 22,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "# define GRU configuration\n",
    "n_batch = 20\n",
    "n_epoch = 400\n",
    "# create LSTM\n",
    "model = Sequential()\n",
    "model.add(GRU(64, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(int(n_out_seq_length)))\n",
    "model.add(GRU(32, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/400\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 0.8410 - accuracy: 0.5137\n",
      "Epoch 2/400\n",
      "1000/1000 [==============================] - 1s 911us/sample - loss: 0.6936 - accuracy: 0.5191\n",
      "Epoch 3/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6934 - accuracy: 0.5154\n",
      "Epoch 4/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6931 - accuracy: 0.5119\n",
      "Epoch 5/400\n",
      "1000/1000 [==============================] - 1s 996us/sample - loss: 0.6930 - accuracy: 0.5136\n",
      "Epoch 6/400\n",
      "1000/1000 [==============================] - 1s 981us/sample - loss: 0.6922 - accuracy: 0.5166\n",
      "Epoch 7/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.6925 - accuracy: 0.5165\n",
      "Epoch 8/400\n",
      "1000/1000 [==============================] - 1s 971us/sample - loss: 0.6927 - accuracy: 0.5150\n",
      "Epoch 9/400\n",
      "1000/1000 [==============================] - 1s 915us/sample - loss: 0.6923 - accuracy: 0.5109\n",
      "Epoch 10/400\n",
      "1000/1000 [==============================] - 1s 961us/sample - loss: 0.6924 - accuracy: 0.5132\n",
      "Epoch 11/400\n",
      "1000/1000 [==============================] - 1s 857us/sample - loss: 0.6920 - accuracy: 0.5154\n",
      "Epoch 12/400\n",
      "1000/1000 [==============================] - 1s 829us/sample - loss: 0.6922 - accuracy: 0.5162\n",
      "Epoch 13/400\n",
      "1000/1000 [==============================] - 1s 941us/sample - loss: 0.6916 - accuracy: 0.5162\n",
      "Epoch 14/400\n",
      "1000/1000 [==============================] - 1s 886us/sample - loss: 0.6917 - accuracy: 0.5187\n",
      "Epoch 15/400\n",
      "1000/1000 [==============================] - 1s 844us/sample - loss: 0.6915 - accuracy: 0.5097\n",
      "Epoch 16/400\n",
      "1000/1000 [==============================] - 1s 945us/sample - loss: 0.6915 - accuracy: 0.5150\n",
      "Epoch 17/400\n",
      "1000/1000 [==============================] - 1s 843us/sample - loss: 0.6912 - accuracy: 0.5191\n",
      "Epoch 18/400\n",
      "1000/1000 [==============================] - 1s 937us/sample - loss: 0.6904 - accuracy: 0.5104\n",
      "Epoch 19/400\n",
      "1000/1000 [==============================] - 1s 935us/sample - loss: 0.6885 - accuracy: 0.5209\n",
      "Epoch 20/400\n",
      "1000/1000 [==============================] - 1s 924us/sample - loss: 0.6847 - accuracy: 0.5291\n",
      "Epoch 21/400\n",
      "1000/1000 [==============================] - 1s 895us/sample - loss: 0.6801 - accuracy: 0.5324\n",
      "Epoch 22/400\n",
      "1000/1000 [==============================] - 1s 795us/sample - loss: 0.6776 - accuracy: 0.5322\n",
      "Epoch 23/400\n",
      "1000/1000 [==============================] - 1s 768us/sample - loss: 0.6781 - accuracy: 0.5294\n",
      "Epoch 24/400\n",
      "1000/1000 [==============================] - 1s 874us/sample - loss: 0.6771 - accuracy: 0.5237\n",
      "Epoch 25/400\n",
      "1000/1000 [==============================] - 1s 776us/sample - loss: 0.6760 - accuracy: 0.5256\n",
      "Epoch 26/400\n",
      "1000/1000 [==============================] - 1s 821us/sample - loss: 0.6762 - accuracy: 0.5291\n",
      "Epoch 27/400\n",
      "1000/1000 [==============================] - 1s 868us/sample - loss: 0.6762 - accuracy: 0.5243\n",
      "Epoch 28/400\n",
      "1000/1000 [==============================] - 1s 942us/sample - loss: 0.6739 - accuracy: 0.5302\n",
      "Epoch 29/400\n",
      "1000/1000 [==============================] - 1s 924us/sample - loss: 0.6688 - accuracy: 0.5410\n",
      "Epoch 30/400\n",
      "1000/1000 [==============================] - 1s 918us/sample - loss: 0.6540 - accuracy: 0.5494\n",
      "Epoch 31/400\n",
      "1000/1000 [==============================] - 1s 836us/sample - loss: 0.6401 - accuracy: 0.5600\n",
      "Epoch 32/400\n",
      "1000/1000 [==============================] - 1s 759us/sample - loss: 0.6304 - accuracy: 0.5676\n",
      "Epoch 33/400\n",
      "1000/1000 [==============================] - 1s 713us/sample - loss: 0.6197 - accuracy: 0.5757\n",
      "Epoch 34/400\n",
      "1000/1000 [==============================] - 1s 754us/sample - loss: 0.6077 - accuracy: 0.5925\n",
      "Epoch 35/400\n",
      "1000/1000 [==============================] - 1s 760us/sample - loss: 0.6112 - accuracy: 0.5835\n",
      "Epoch 36/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5991 - accuracy: 0.6006\n",
      "Epoch 37/400\n",
      "1000/1000 [==============================] - 1s 962us/sample - loss: 0.5924 - accuracy: 0.6155\n",
      "Epoch 38/400\n",
      "1000/1000 [==============================] - 1s 933us/sample - loss: 0.5834 - accuracy: 0.6234\n",
      "Epoch 39/400\n",
      "1000/1000 [==============================] - 1s 782us/sample - loss: 0.5818 - accuracy: 0.6247\n",
      "Epoch 40/400\n",
      "1000/1000 [==============================] - 1s 977us/sample - loss: 0.5767 - accuracy: 0.6297\n",
      "Epoch 41/400\n",
      "1000/1000 [==============================] - 1s 898us/sample - loss: 0.5648 - accuracy: 0.6297\n",
      "Epoch 42/400\n",
      "1000/1000 [==============================] - 1s 933us/sample - loss: 0.5594 - accuracy: 0.6435\n",
      "Epoch 43/400\n",
      "1000/1000 [==============================] - 1s 924us/sample - loss: 0.5547 - accuracy: 0.6395\n",
      "Epoch 44/400\n",
      "1000/1000 [==============================] - 1s 922us/sample - loss: 0.5474 - accuracy: 0.6443\n",
      "Epoch 45/400\n",
      "1000/1000 [==============================] - 1s 890us/sample - loss: 0.5538 - accuracy: 0.6399\n",
      "Epoch 46/400\n",
      "1000/1000 [==============================] - 1s 948us/sample - loss: 0.5739 - accuracy: 0.6235\n",
      "Epoch 47/400\n",
      "1000/1000 [==============================] - 1s 961us/sample - loss: 0.5422 - accuracy: 0.6461\n",
      "Epoch 48/400\n",
      "1000/1000 [==============================] - 1s 895us/sample - loss: 0.5353 - accuracy: 0.6571\n",
      "Epoch 49/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5460 - accuracy: 0.6476\n",
      "Epoch 50/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5282 - accuracy: 0.6590\n",
      "Epoch 51/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5355 - accuracy: 0.6551\n",
      "Epoch 52/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5254 - accuracy: 0.6601\n",
      "Epoch 53/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5220 - accuracy: 0.6652\n",
      "Epoch 54/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5375 - accuracy: 0.6576\n",
      "Epoch 55/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5303 - accuracy: 0.6620\n",
      "Epoch 56/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5073 - accuracy: 0.6819\n",
      "Epoch 57/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5076 - accuracy: 0.6794\n",
      "Epoch 58/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4990 - accuracy: 0.6878\n",
      "Epoch 59/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5295 - accuracy: 0.6660\n",
      "Epoch 60/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5066 - accuracy: 0.6814\n",
      "Epoch 61/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4864 - accuracy: 0.6942\n",
      "Epoch 62/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.5253 - accuracy: 0.6713\n",
      "Epoch 63/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4841 - accuracy: 0.7020\n",
      "Epoch 64/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4805 - accuracy: 0.6996\n",
      "Epoch 65/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4858 - accuracy: 0.6948\n",
      "Epoch 66/400\n",
      "1000/1000 [==============================] - 1s 993us/sample - loss: 0.4839 - accuracy: 0.7001\n",
      "Epoch 67/400\n",
      "1000/1000 [==============================] - 1s 963us/sample - loss: 0.4650 - accuracy: 0.7143\n",
      "Epoch 68/400\n",
      "1000/1000 [==============================] - 1s 952us/sample - loss: 0.4850 - accuracy: 0.7000\n",
      "Epoch 69/400\n",
      "1000/1000 [==============================] - 1s 970us/sample - loss: 0.4611 - accuracy: 0.7153\n",
      "Epoch 70/400\n",
      "1000/1000 [==============================] - 1s 933us/sample - loss: 0.4765 - accuracy: 0.7078\n",
      "Epoch 71/400\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.5185 - accuracy: 0.6723\n",
      "Epoch 72/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4624 - accuracy: 0.7159\n",
      "Epoch 73/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4590 - accuracy: 0.7167\n",
      "Epoch 74/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4474 - accuracy: 0.7265\n",
      "Epoch 75/400\n",
      "1000/1000 [==============================] - 1s 930us/sample - loss: 0.4480 - accuracy: 0.7275\n",
      "Epoch 76/400\n",
      "1000/1000 [==============================] - 1s 941us/sample - loss: 0.5017 - accuracy: 0.6981\n",
      "Epoch 77/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 917us/sample - loss: 0.5314 - accuracy: 0.6676\n",
      "Epoch 78/400\n",
      "1000/1000 [==============================] - 1s 857us/sample - loss: 0.4629 - accuracy: 0.7154\n",
      "Epoch 79/400\n",
      "1000/1000 [==============================] - 1s 942us/sample - loss: 0.4432 - accuracy: 0.7288\n",
      "Epoch 80/400\n",
      "1000/1000 [==============================] - 1s 954us/sample - loss: 0.4579 - accuracy: 0.7205\n",
      "Epoch 81/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4354 - accuracy: 0.7369\n",
      "Epoch 82/400\n",
      "1000/1000 [==============================] - 1s 889us/sample - loss: 0.4487 - accuracy: 0.7205\n",
      "Epoch 83/400\n",
      "1000/1000 [==============================] - 1s 932us/sample - loss: 0.5503 - accuracy: 0.6735\n",
      "Epoch 84/400\n",
      "1000/1000 [==============================] - 1s 894us/sample - loss: 0.5222 - accuracy: 0.6703\n",
      "Epoch 85/400\n",
      "1000/1000 [==============================] - 1s 901us/sample - loss: 0.4452 - accuracy: 0.7324\n",
      "Epoch 86/400\n",
      "1000/1000 [==============================] - 1s 913us/sample - loss: 0.4328 - accuracy: 0.7394\n",
      "Epoch 87/400\n",
      "1000/1000 [==============================] - 1s 882us/sample - loss: 0.4266 - accuracy: 0.7385\n",
      "Epoch 88/400\n",
      "1000/1000 [==============================] - 1s 930us/sample - loss: 0.4267 - accuracy: 0.7406\n",
      "Epoch 89/400\n",
      "1000/1000 [==============================] - 1s 893us/sample - loss: 0.4275 - accuracy: 0.7390\n",
      "Epoch 90/400\n",
      "1000/1000 [==============================] - 1s 886us/sample - loss: 0.4183 - accuracy: 0.7469\n",
      "Epoch 91/400\n",
      "1000/1000 [==============================] - 1s 857us/sample - loss: 0.4136 - accuracy: 0.7490\n",
      "Epoch 92/400\n",
      "1000/1000 [==============================] - 1s 917us/sample - loss: 0.4177 - accuracy: 0.7414\n",
      "Epoch 93/400\n",
      "1000/1000 [==============================] - 1s 905us/sample - loss: 0.4375 - accuracy: 0.7290\n",
      "Epoch 94/400\n",
      "1000/1000 [==============================] - 1s 898us/sample - loss: 0.4242 - accuracy: 0.7363\n",
      "Epoch 95/400\n",
      "1000/1000 [==============================] - 1s 948us/sample - loss: 0.4106 - accuracy: 0.7447\n",
      "Epoch 96/400\n",
      "1000/1000 [==============================] - 1s 927us/sample - loss: 0.4104 - accuracy: 0.7503\n",
      "Epoch 97/400\n",
      "1000/1000 [==============================] - 1s 895us/sample - loss: 0.4032 - accuracy: 0.7539\n",
      "Epoch 98/400\n",
      "1000/1000 [==============================] - 1s 916us/sample - loss: 0.3987 - accuracy: 0.7558\n",
      "Epoch 99/400\n",
      "1000/1000 [==============================] - 1s 910us/sample - loss: 0.4102 - accuracy: 0.7482\n",
      "Epoch 100/400\n",
      "1000/1000 [==============================] - 1s 938us/sample - loss: 0.4393 - accuracy: 0.7292\n",
      "Epoch 101/400\n",
      "1000/1000 [==============================] - 1s 884us/sample - loss: 0.4192 - accuracy: 0.7432\n",
      "Epoch 102/400\n",
      "1000/1000 [==============================] - 1s 916us/sample - loss: 0.4267 - accuracy: 0.7405\n",
      "Epoch 103/400\n",
      "1000/1000 [==============================] - 1s 810us/sample - loss: 0.4003 - accuracy: 0.7529\n",
      "Epoch 104/400\n",
      "1000/1000 [==============================] - 1s 748us/sample - loss: 0.3976 - accuracy: 0.7583\n",
      "Epoch 105/400\n",
      "1000/1000 [==============================] - 1s 770us/sample - loss: 0.4038 - accuracy: 0.7551\n",
      "Epoch 106/400\n",
      "1000/1000 [==============================] - 1s 726us/sample - loss: 0.4304 - accuracy: 0.7341\n",
      "Epoch 107/400\n",
      "1000/1000 [==============================] - 1s 728us/sample - loss: 0.4390 - accuracy: 0.7301\n",
      "Epoch 108/400\n",
      "1000/1000 [==============================] - 1s 736us/sample - loss: 0.4056 - accuracy: 0.7508\n",
      "Epoch 109/400\n",
      "1000/1000 [==============================] - 1s 729us/sample - loss: 0.4177 - accuracy: 0.7495\n",
      "Epoch 110/400\n",
      "1000/1000 [==============================] - 1s 733us/sample - loss: 0.4035 - accuracy: 0.7527\n",
      "Epoch 111/400\n",
      "1000/1000 [==============================] - 1s 738us/sample - loss: 0.3947 - accuracy: 0.7590\n",
      "Epoch 112/400\n",
      "1000/1000 [==============================] - 1s 727us/sample - loss: 0.4028 - accuracy: 0.7511\n",
      "Epoch 113/400\n",
      "1000/1000 [==============================] - 1s 717us/sample - loss: 0.3924 - accuracy: 0.7573\n",
      "Epoch 114/400\n",
      "1000/1000 [==============================] - 1s 765us/sample - loss: 0.3869 - accuracy: 0.7642\n",
      "Epoch 115/400\n",
      "1000/1000 [==============================] - 1s 722us/sample - loss: 0.3897 - accuracy: 0.7580\n",
      "Epoch 116/400\n",
      "1000/1000 [==============================] - 1s 716us/sample - loss: 0.3923 - accuracy: 0.7604\n",
      "Epoch 117/400\n",
      "1000/1000 [==============================] - 1s 724us/sample - loss: 0.3891 - accuracy: 0.7588\n",
      "Epoch 118/400\n",
      "1000/1000 [==============================] - 1s 729us/sample - loss: 0.3825 - accuracy: 0.7624\n",
      "Epoch 119/400\n",
      "1000/1000 [==============================] - 1s 716us/sample - loss: 0.3828 - accuracy: 0.7643\n",
      "Epoch 120/400\n",
      "1000/1000 [==============================] - 1s 723us/sample - loss: 0.3780 - accuracy: 0.7685\n",
      "Epoch 121/400\n",
      "1000/1000 [==============================] - 1s 727us/sample - loss: 0.3829 - accuracy: 0.7653\n",
      "Epoch 122/400\n",
      "1000/1000 [==============================] - 1s 754us/sample - loss: 0.3848 - accuracy: 0.7640\n",
      "Epoch 123/400\n",
      "1000/1000 [==============================] - 1s 758us/sample - loss: 0.3777 - accuracy: 0.7711\n",
      "Epoch 124/400\n",
      "1000/1000 [==============================] - 1s 718us/sample - loss: 0.5843 - accuracy: 0.6882\n",
      "Epoch 125/400\n",
      "1000/1000 [==============================] - 1s 724us/sample - loss: 0.5217 - accuracy: 0.6798\n",
      "Epoch 126/400\n",
      "1000/1000 [==============================] - 1s 733us/sample - loss: 0.4410 - accuracy: 0.7308\n",
      "Epoch 127/400\n",
      "1000/1000 [==============================] - 1s 724us/sample - loss: 0.4173 - accuracy: 0.7478\n",
      "Epoch 128/400\n",
      "1000/1000 [==============================] - 1s 729us/sample - loss: 0.4074 - accuracy: 0.7556\n",
      "Epoch 129/400\n",
      "1000/1000 [==============================] - 1s 744us/sample - loss: 0.4020 - accuracy: 0.7573\n",
      "Epoch 130/400\n",
      "1000/1000 [==============================] - 1s 765us/sample - loss: 0.4001 - accuracy: 0.7552\n",
      "Epoch 131/400\n",
      "1000/1000 [==============================] - 1s 758us/sample - loss: 0.3930 - accuracy: 0.7600\n",
      "Epoch 132/400\n",
      "1000/1000 [==============================] - 1s 748us/sample - loss: 0.4009 - accuracy: 0.7553\n",
      "Epoch 133/400\n",
      "1000/1000 [==============================] - 1s 895us/sample - loss: 0.4010 - accuracy: 0.7546\n",
      "Epoch 134/400\n",
      "1000/1000 [==============================] - 1s 775us/sample - loss: 0.4160 - accuracy: 0.7409\n",
      "Epoch 135/400\n",
      "1000/1000 [==============================] - 1s 734us/sample - loss: 0.3890 - accuracy: 0.7660\n",
      "Epoch 136/400\n",
      "1000/1000 [==============================] - 1s 732us/sample - loss: 0.3788 - accuracy: 0.7692\n",
      "Epoch 137/400\n",
      "1000/1000 [==============================] - 1s 723us/sample - loss: 0.3773 - accuracy: 0.7683\n",
      "Epoch 138/400\n",
      "1000/1000 [==============================] - 1s 769us/sample - loss: 0.3714 - accuracy: 0.7723\n",
      "Epoch 139/400\n",
      "1000/1000 [==============================] - 1s 753us/sample - loss: 0.3683 - accuracy: 0.7760\n",
      "Epoch 140/400\n",
      "1000/1000 [==============================] - 1s 769us/sample - loss: 0.3711 - accuracy: 0.7757\n",
      "Epoch 141/400\n",
      "1000/1000 [==============================] - 1s 755us/sample - loss: 0.5182 - accuracy: 0.7050\n",
      "Epoch 142/400\n",
      "1000/1000 [==============================] - 1s 738us/sample - loss: 0.4718 - accuracy: 0.7036\n",
      "Epoch 143/400\n",
      "1000/1000 [==============================] - 1s 741us/sample - loss: 0.3971 - accuracy: 0.7606\n",
      "Epoch 144/400\n",
      "1000/1000 [==============================] - 1s 811us/sample - loss: 0.3886 - accuracy: 0.7625\n",
      "Epoch 145/400\n",
      "1000/1000 [==============================] - 1s 812us/sample - loss: 0.3751 - accuracy: 0.7728\n",
      "Epoch 146/400\n",
      "1000/1000 [==============================] - 1s 781us/sample - loss: 0.3652 - accuracy: 0.7848\n",
      "Epoch 147/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3710 - accuracy: 0.7783\n",
      "Epoch 148/400\n",
      "1000/1000 [==============================] - 1s 901us/sample - loss: 0.3624 - accuracy: 0.7810\n",
      "Epoch 149/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4001 - accuracy: 0.7547\n",
      "Epoch 150/400\n",
      "1000/1000 [==============================] - 1s 905us/sample - loss: 0.4659 - accuracy: 0.7227\n",
      "Epoch 151/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3764 - accuracy: 0.7707\n",
      "Epoch 152/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3614 - accuracy: 0.7851\n",
      "Epoch 153/400\n",
      "1000/1000 [==============================] - 1s 909us/sample - loss: 0.3587 - accuracy: 0.7853\n",
      "Epoch 154/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3607 - accuracy: 0.7872\n",
      "Epoch 155/400\n",
      "1000/1000 [==============================] - 1s 916us/sample - loss: 0.3604 - accuracy: 0.7810\n",
      "Epoch 156/400\n",
      "1000/1000 [==============================] - 1s 888us/sample - loss: 0.3693 - accuracy: 0.7792\n",
      "Epoch 157/400\n",
      "1000/1000 [==============================] - 1s 821us/sample - loss: 0.3709 - accuracy: 0.7751\n",
      "Epoch 158/400\n",
      "1000/1000 [==============================] - 1s 863us/sample - loss: 0.3641 - accuracy: 0.7793\n",
      "Epoch 159/400\n",
      "1000/1000 [==============================] - 1s 860us/sample - loss: 0.3581 - accuracy: 0.7844\n",
      "Epoch 160/400\n",
      "1000/1000 [==============================] - 1s 818us/sample - loss: 0.3576 - accuracy: 0.7841\n",
      "Epoch 161/400\n",
      "1000/1000 [==============================] - 1s 826us/sample - loss: 0.4556 - accuracy: 0.7316\n",
      "Epoch 162/400\n",
      "1000/1000 [==============================] - 1s 814us/sample - loss: 0.5017 - accuracy: 0.7157\n",
      "Epoch 163/400\n",
      "1000/1000 [==============================] - 1s 800us/sample - loss: 0.3677 - accuracy: 0.7828\n",
      "Epoch 164/400\n",
      "1000/1000 [==============================] - 1s 872us/sample - loss: 0.3531 - accuracy: 0.7913\n",
      "Epoch 165/400\n",
      "1000/1000 [==============================] - 1s 808us/sample - loss: 0.3546 - accuracy: 0.7899\n",
      "Epoch 166/400\n",
      "1000/1000 [==============================] - 1s 803us/sample - loss: 0.3541 - accuracy: 0.7919\n",
      "Epoch 167/400\n",
      "1000/1000 [==============================] - 1s 806us/sample - loss: 0.3524 - accuracy: 0.7899\n",
      "Epoch 168/400\n",
      "1000/1000 [==============================] - 1s 799us/sample - loss: 0.3482 - accuracy: 0.7955\n",
      "Epoch 169/400\n",
      "1000/1000 [==============================] - 1s 793us/sample - loss: 0.3470 - accuracy: 0.7918\n",
      "Epoch 170/400\n",
      "1000/1000 [==============================] - 1s 801us/sample - loss: 0.3471 - accuracy: 0.7925\n",
      "Epoch 171/400\n",
      "1000/1000 [==============================] - 1s 861us/sample - loss: 0.3434 - accuracy: 0.7965\n",
      "Epoch 172/400\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.3440 - accuracy: 0.7935\n",
      "Epoch 173/400\n",
      "1000/1000 [==============================] - 1s 811us/sample - loss: 0.3447 - accuracy: 0.7966\n",
      "Epoch 174/400\n",
      "1000/1000 [==============================] - 1s 816us/sample - loss: 0.3422 - accuracy: 0.7969\n",
      "Epoch 175/400\n",
      "1000/1000 [==============================] - 1s 796us/sample - loss: 0.3615 - accuracy: 0.7847\n",
      "Epoch 176/400\n",
      "1000/1000 [==============================] - 1s 792us/sample - loss: 0.4926 - accuracy: 0.7259\n",
      "Epoch 177/400\n",
      "1000/1000 [==============================] - 1s 782us/sample - loss: 0.4390 - accuracy: 0.7423\n",
      "Epoch 178/400\n",
      "1000/1000 [==============================] - 1s 823us/sample - loss: 0.3472 - accuracy: 0.7939\n",
      "Epoch 179/400\n",
      "1000/1000 [==============================] - 1s 792us/sample - loss: 0.3428 - accuracy: 0.7952\n",
      "Epoch 180/400\n",
      "1000/1000 [==============================] - 1s 783us/sample - loss: 0.3414 - accuracy: 0.7971\n",
      "Epoch 181/400\n",
      "1000/1000 [==============================] - 1s 770us/sample - loss: 0.3429 - accuracy: 0.7976\n",
      "Epoch 182/400\n",
      "1000/1000 [==============================] - 1s 762us/sample - loss: 0.3418 - accuracy: 0.8015\n",
      "Epoch 183/400\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.3412 - accuracy: 0.7950\n",
      "Epoch 184/400\n",
      "1000/1000 [==============================] - 1s 803us/sample - loss: 0.3415 - accuracy: 0.7959\n",
      "Epoch 185/400\n",
      "1000/1000 [==============================] - 1s 795us/sample - loss: 0.3751 - accuracy: 0.7791\n",
      "Epoch 186/400\n",
      "1000/1000 [==============================] - 1s 798us/sample - loss: 0.3696 - accuracy: 0.7840\n",
      "Epoch 187/400\n",
      "1000/1000 [==============================] - 1s 789us/sample - loss: 0.3450 - accuracy: 0.7965\n",
      "Epoch 188/400\n",
      "1000/1000 [==============================] - 1s 816us/sample - loss: 0.3398 - accuracy: 0.8006\n",
      "Epoch 189/400\n",
      "1000/1000 [==============================] - 1s 797us/sample - loss: 0.3361 - accuracy: 0.8019\n",
      "Epoch 190/400\n",
      "1000/1000 [==============================] - 1s 822us/sample - loss: 0.3354 - accuracy: 0.7992\n",
      "Epoch 191/400\n",
      "1000/1000 [==============================] - 1s 797us/sample - loss: 0.3341 - accuracy: 0.8043\n",
      "Epoch 192/400\n",
      "1000/1000 [==============================] - 1s 795us/sample - loss: 0.3376 - accuracy: 0.8016\n",
      "Epoch 193/400\n",
      "1000/1000 [==============================] - 1s 797us/sample - loss: 0.3489 - accuracy: 0.7966\n",
      "Epoch 194/400\n",
      "1000/1000 [==============================] - 1s 781us/sample - loss: 0.3328 - accuracy: 0.8040\n",
      "Epoch 195/400\n",
      "1000/1000 [==============================] - 1s 792us/sample - loss: 0.3398 - accuracy: 0.7975\n",
      "Epoch 196/400\n",
      "1000/1000 [==============================] - 1s 852us/sample - loss: 0.3324 - accuracy: 0.8036\n",
      "Epoch 197/400\n",
      "1000/1000 [==============================] - 1s 842us/sample - loss: 0.3692 - accuracy: 0.7838\n",
      "Epoch 198/400\n",
      "1000/1000 [==============================] - 1s 868us/sample - loss: 0.3410 - accuracy: 0.7961\n",
      "Epoch 199/400\n",
      "1000/1000 [==============================] - 1s 851us/sample - loss: 0.3299 - accuracy: 0.8042\n",
      "Epoch 200/400\n",
      "1000/1000 [==============================] - 1s 764us/sample - loss: 0.3309 - accuracy: 0.8019\n",
      "Epoch 201/400\n",
      "1000/1000 [==============================] - 1s 764us/sample - loss: 0.3308 - accuracy: 0.8042\n",
      "Epoch 202/400\n",
      "1000/1000 [==============================] - 1s 825us/sample - loss: 0.4100 - accuracy: 0.7696\n",
      "Epoch 203/400\n",
      "1000/1000 [==============================] - 1s 832us/sample - loss: 0.4086 - accuracy: 0.7610\n",
      "Epoch 204/400\n",
      "1000/1000 [==============================] - 1s 887us/sample - loss: 0.3328 - accuracy: 0.8026\n",
      "Epoch 205/400\n",
      "1000/1000 [==============================] - 1s 837us/sample - loss: 0.3264 - accuracy: 0.8104\n",
      "Epoch 206/400\n",
      "1000/1000 [==============================] - 1s 824us/sample - loss: 0.3285 - accuracy: 0.8079\n",
      "Epoch 207/400\n",
      "1000/1000 [==============================] - 1s 821us/sample - loss: 0.3287 - accuracy: 0.8085\n",
      "Epoch 208/400\n",
      "1000/1000 [==============================] - 1s 841us/sample - loss: 0.3278 - accuracy: 0.8048\n",
      "Epoch 209/400\n",
      "1000/1000 [==============================] - 1s 832us/sample - loss: 0.3400 - accuracy: 0.7974\n",
      "Epoch 210/400\n",
      "1000/1000 [==============================] - 1s 831us/sample - loss: 0.3293 - accuracy: 0.8069\n",
      "Epoch 211/400\n",
      "1000/1000 [==============================] - 1s 858us/sample - loss: 0.3331 - accuracy: 0.8053\n",
      "Epoch 212/400\n",
      "1000/1000 [==============================] - 1s 935us/sample - loss: 0.3268 - accuracy: 0.8047\n",
      "Epoch 213/400\n",
      "1000/1000 [==============================] - 1s 841us/sample - loss: 0.3249 - accuracy: 0.8078\n",
      "Epoch 214/400\n",
      "1000/1000 [==============================] - 1s 847us/sample - loss: 0.3208 - accuracy: 0.8118\n",
      "Epoch 215/400\n",
      "1000/1000 [==============================] - 1s 839us/sample - loss: 0.3944 - accuracy: 0.7779\n",
      "Epoch 216/400\n",
      "1000/1000 [==============================] - 1s 852us/sample - loss: 0.4028 - accuracy: 0.7649\n",
      "Epoch 217/400\n",
      "1000/1000 [==============================] - 1s 833us/sample - loss: 0.3522 - accuracy: 0.7949\n",
      "Epoch 218/400\n",
      "1000/1000 [==============================] - 1s 841us/sample - loss: 0.4042 - accuracy: 0.7738\n",
      "Epoch 219/400\n",
      "1000/1000 [==============================] - 1s 840us/sample - loss: 0.3869 - accuracy: 0.7768\n",
      "Epoch 220/400\n",
      "1000/1000 [==============================] - 1s 848us/sample - loss: 0.3277 - accuracy: 0.8079\n",
      "Epoch 221/400\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.3212 - accuracy: 0.8114\n",
      "Epoch 222/400\n",
      "1000/1000 [==============================] - 1s 837us/sample - loss: 0.3224 - accuracy: 0.8067\n",
      "Epoch 223/400\n",
      "1000/1000 [==============================] - 1s 832us/sample - loss: 0.3210 - accuracy: 0.8095\n",
      "Epoch 224/400\n",
      "1000/1000 [==============================] - 1s 832us/sample - loss: 0.3202 - accuracy: 0.8135\n",
      "Epoch 225/400\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.3237 - accuracy: 0.8079\n",
      "Epoch 226/400\n",
      "1000/1000 [==============================] - 1s 835us/sample - loss: 0.3170 - accuracy: 0.8140\n",
      "Epoch 227/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 821us/sample - loss: 0.3157 - accuracy: 0.8175\n",
      "Epoch 228/400\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.3178 - accuracy: 0.8122\n",
      "Epoch 229/400\n",
      "1000/1000 [==============================] - 1s 836us/sample - loss: 0.3205 - accuracy: 0.8149\n",
      "Epoch 230/400\n",
      "1000/1000 [==============================] - 1s 824us/sample - loss: 0.3177 - accuracy: 0.8128\n",
      "Epoch 231/400\n",
      "1000/1000 [==============================] - 1s 857us/sample - loss: 0.3206 - accuracy: 0.8107\n",
      "Epoch 232/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3202 - accuracy: 0.8106\n",
      "Epoch 233/400\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.3160 - accuracy: 0.8182\n",
      "Epoch 234/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3348 - accuracy: 0.8061\n",
      "Epoch 235/400\n",
      "1000/1000 [==============================] - 2s 2ms/sample - loss: 0.3204 - accuracy: 0.8114\n",
      "Epoch 236/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3674 - accuracy: 0.7871\n",
      "Epoch 237/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3194 - accuracy: 0.8109\n",
      "Epoch 238/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3159 - accuracy: 0.8122\n",
      "Epoch 239/400\n",
      "1000/1000 [==============================] - 1s 896us/sample - loss: 0.3148 - accuracy: 0.8131\n",
      "Epoch 240/400\n",
      "1000/1000 [==============================] - 1s 870us/sample - loss: 0.3143 - accuracy: 0.8177\n",
      "Epoch 241/400\n",
      "1000/1000 [==============================] - 1s 828us/sample - loss: 0.3150 - accuracy: 0.8154\n",
      "Epoch 242/400\n",
      "1000/1000 [==============================] - 1s 833us/sample - loss: 0.3154 - accuracy: 0.8141\n",
      "Epoch 243/400\n",
      "1000/1000 [==============================] - 1s 840us/sample - loss: 0.3182 - accuracy: 0.8146\n",
      "Epoch 244/400\n",
      "1000/1000 [==============================] - 1s 844us/sample - loss: 0.3220 - accuracy: 0.8126\n",
      "Epoch 245/400\n",
      "1000/1000 [==============================] - 1s 928us/sample - loss: 0.3511 - accuracy: 0.7957\n",
      "Epoch 246/400\n",
      "1000/1000 [==============================] - 1s 913us/sample - loss: 0.3254 - accuracy: 0.8104\n",
      "Epoch 247/400\n",
      "1000/1000 [==============================] - 1s 883us/sample - loss: 0.3172 - accuracy: 0.8114\n",
      "Epoch 248/400\n",
      "1000/1000 [==============================] - 1s 801us/sample - loss: 0.3152 - accuracy: 0.8173\n",
      "Epoch 249/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3084 - accuracy: 0.8168\n",
      "Epoch 250/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3055 - accuracy: 0.8199\n",
      "Epoch 251/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.4989 - accuracy: 0.7537\n",
      "Epoch 252/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3369 - accuracy: 0.8027\n",
      "Epoch 253/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3069 - accuracy: 0.8166\n",
      "Epoch 254/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3097 - accuracy: 0.8182\n",
      "Epoch 255/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3197 - accuracy: 0.8141\n",
      "Epoch 256/400\n",
      "1000/1000 [==============================] - 1s 791us/sample - loss: 0.3540 - accuracy: 0.7974\n",
      "Epoch 257/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3231 - accuracy: 0.8118\n",
      "Epoch 258/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3086 - accuracy: 0.8201\n",
      "Epoch 259/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3094 - accuracy: 0.8183\n",
      "Epoch 260/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3008 - accuracy: 0.8247\n",
      "Epoch 261/400\n",
      "1000/1000 [==============================] - 1s 902us/sample - loss: 0.3001 - accuracy: 0.8234\n",
      "Epoch 262/400\n",
      "1000/1000 [==============================] - 1s 972us/sample - loss: 0.3220 - accuracy: 0.8139\n",
      "Epoch 263/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3198 - accuracy: 0.8137\n",
      "Epoch 264/400\n",
      "1000/1000 [==============================] - 1s 906us/sample - loss: 0.3055 - accuracy: 0.8157\n",
      "Epoch 265/400\n",
      "1000/1000 [==============================] - 1s 877us/sample - loss: 0.3062 - accuracy: 0.8175\n",
      "Epoch 266/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3004 - accuracy: 0.8247\n",
      "Epoch 267/400\n",
      "1000/1000 [==============================] - 1s 985us/sample - loss: 0.3065 - accuracy: 0.8211\n",
      "Epoch 268/400\n",
      "1000/1000 [==============================] - 1s 904us/sample - loss: 0.3008 - accuracy: 0.8249\n",
      "Epoch 269/400\n",
      "1000/1000 [==============================] - 1s 952us/sample - loss: 0.3000 - accuracy: 0.8222\n",
      "Epoch 270/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3055 - accuracy: 0.8178\n",
      "Epoch 271/400\n",
      "1000/1000 [==============================] - 1s 808us/sample - loss: 0.3144 - accuracy: 0.8137\n",
      "Epoch 272/400\n",
      "1000/1000 [==============================] - 1s 784us/sample - loss: 0.3093 - accuracy: 0.8220\n",
      "Epoch 273/400\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.3072 - accuracy: 0.8195\n",
      "Epoch 274/400\n",
      "1000/1000 [==============================] - 1s 913us/sample - loss: 0.3049 - accuracy: 0.8189\n",
      "Epoch 275/400\n",
      "1000/1000 [==============================] - 1s 951us/sample - loss: 0.3020 - accuracy: 0.8218\n",
      "Epoch 276/400\n",
      "1000/1000 [==============================] - 1s 905us/sample - loss: 0.3060 - accuracy: 0.8177\n",
      "Epoch 277/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3020 - accuracy: 0.8221\n",
      "Epoch 278/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2997 - accuracy: 0.8282\n",
      "Epoch 279/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3476 - accuracy: 0.8074\n",
      "Epoch 280/400\n",
      "1000/1000 [==============================] - 1s 950us/sample - loss: 0.4414 - accuracy: 0.7671\n",
      "Epoch 281/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3624 - accuracy: 0.7943\n",
      "Epoch 282/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3019 - accuracy: 0.8234\n",
      "Epoch 283/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3002 - accuracy: 0.8279\n",
      "Epoch 284/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2988 - accuracy: 0.8277\n",
      "Epoch 285/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2966 - accuracy: 0.8282\n",
      "Epoch 286/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2950 - accuracy: 0.8312\n",
      "Epoch 287/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2949 - accuracy: 0.8264\n",
      "Epoch 288/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2908 - accuracy: 0.8289\n",
      "Epoch 289/400\n",
      "1000/1000 [==============================] - 1s 928us/sample - loss: 0.2979 - accuracy: 0.8250\n",
      "Epoch 290/400\n",
      "1000/1000 [==============================] - 1s 803us/sample - loss: 0.3834 - accuracy: 0.7927\n",
      "Epoch 291/400\n",
      "1000/1000 [==============================] - 1s 860us/sample - loss: 0.3119 - accuracy: 0.8152\n",
      "Epoch 292/400\n",
      "1000/1000 [==============================] - 1s 898us/sample - loss: 0.2929 - accuracy: 0.8336\n",
      "Epoch 293/400\n",
      "1000/1000 [==============================] - 1s 816us/sample - loss: 0.2910 - accuracy: 0.8337\n",
      "Epoch 294/400\n",
      "1000/1000 [==============================] - 1s 880us/sample - loss: 0.2941 - accuracy: 0.8309\n",
      "Epoch 295/400\n",
      "1000/1000 [==============================] - 1s 882us/sample - loss: 0.2997 - accuracy: 0.8293\n",
      "Epoch 296/400\n",
      "1000/1000 [==============================] - 1s 866us/sample - loss: 0.2904 - accuracy: 0.8331\n",
      "Epoch 297/400\n",
      "1000/1000 [==============================] - 1s 806us/sample - loss: 0.2872 - accuracy: 0.8367\n",
      "Epoch 298/400\n",
      "1000/1000 [==============================] - 1s 878us/sample - loss: 0.2936 - accuracy: 0.8313\n",
      "Epoch 299/400\n",
      "1000/1000 [==============================] - 1s 851us/sample - loss: 0.2975 - accuracy: 0.8283\n",
      "Epoch 300/400\n",
      "1000/1000 [==============================] - 1s 970us/sample - loss: 0.2870 - accuracy: 0.8354\n",
      "Epoch 301/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2894 - accuracy: 0.8331\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2979 - accuracy: 0.8295\n",
      "Epoch 303/400\n",
      "1000/1000 [==============================] - 1s 842us/sample - loss: 0.2964 - accuracy: 0.8306\n",
      "Epoch 304/400\n",
      "1000/1000 [==============================] - 1s 972us/sample - loss: 0.2982 - accuracy: 0.8278\n",
      "Epoch 305/400\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.3147 - accuracy: 0.8239\n",
      "Epoch 306/400\n",
      "1000/1000 [==============================] - 1s 764us/sample - loss: 0.3545 - accuracy: 0.8019\n",
      "Epoch 307/400\n",
      "1000/1000 [==============================] - 1s 782us/sample - loss: 0.3177 - accuracy: 0.8181\n",
      "Epoch 308/400\n",
      "1000/1000 [==============================] - 1s 811us/sample - loss: 0.2934 - accuracy: 0.8296\n",
      "Epoch 309/400\n",
      "1000/1000 [==============================] - 1s 785us/sample - loss: 0.2864 - accuracy: 0.8372\n",
      "Epoch 310/400\n",
      "1000/1000 [==============================] - 1s 879us/sample - loss: 0.2819 - accuracy: 0.8398\n",
      "Epoch 311/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2861 - accuracy: 0.8329\n",
      "Epoch 312/400\n",
      "1000/1000 [==============================] - 1s 919us/sample - loss: 0.2844 - accuracy: 0.8353\n",
      "Epoch 313/400\n",
      "1000/1000 [==============================] - 1s 783us/sample - loss: 0.2851 - accuracy: 0.8376\n",
      "Epoch 314/400\n",
      "1000/1000 [==============================] - 1s 784us/sample - loss: 0.2869 - accuracy: 0.8369\n",
      "Epoch 315/400\n",
      "1000/1000 [==============================] - 1s 874us/sample - loss: 0.2881 - accuracy: 0.8308\n",
      "Epoch 316/400\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.2968 - accuracy: 0.8336\n",
      "Epoch 317/400\n",
      "1000/1000 [==============================] - 1s 893us/sample - loss: 0.2891 - accuracy: 0.8338\n",
      "Epoch 318/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2747 - accuracy: 0.8411\n",
      "Epoch 319/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2791 - accuracy: 0.8409\n",
      "Epoch 320/400\n",
      "1000/1000 [==============================] - 1s 934us/sample - loss: 0.2874 - accuracy: 0.8373\n",
      "Epoch 321/400\n",
      "1000/1000 [==============================] - 1s 907us/sample - loss: 0.2858 - accuracy: 0.8382\n",
      "Epoch 322/400\n",
      "1000/1000 [==============================] - 1s 989us/sample - loss: 0.3318 - accuracy: 0.8171\n",
      "Epoch 323/400\n",
      "1000/1000 [==============================] - 1s 903us/sample - loss: 0.4861 - accuracy: 0.7631\n",
      "Epoch 324/400\n",
      "1000/1000 [==============================] - 1s 923us/sample - loss: 0.3748 - accuracy: 0.7934\n",
      "Epoch 325/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2953 - accuracy: 0.83260s - loss: 0.3022 \n",
      "Epoch 326/400\n",
      "1000/1000 [==============================] - 1s 898us/sample - loss: 0.2817 - accuracy: 0.8388\n",
      "Epoch 327/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2800 - accuracy: 0.8404\n",
      "Epoch 328/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2754 - accuracy: 0.8435\n",
      "Epoch 329/400\n",
      "1000/1000 [==============================] - 1s 886us/sample - loss: 0.2754 - accuracy: 0.8432\n",
      "Epoch 330/400\n",
      "1000/1000 [==============================] - 1s 783us/sample - loss: 0.2747 - accuracy: 0.8453\n",
      "Epoch 331/400\n",
      "1000/1000 [==============================] - 1s 810us/sample - loss: 0.2708 - accuracy: 0.8450\n",
      "Epoch 332/400\n",
      "1000/1000 [==============================] - 1s 991us/sample - loss: 0.2764 - accuracy: 0.8458\n",
      "Epoch 333/400\n",
      "1000/1000 [==============================] - 1s 968us/sample - loss: 0.2728 - accuracy: 0.8475\n",
      "Epoch 334/400\n",
      "1000/1000 [==============================] - 1s 817us/sample - loss: 0.2816 - accuracy: 0.8435\n",
      "Epoch 335/400\n",
      "1000/1000 [==============================] - 1s 793us/sample - loss: 0.2767 - accuracy: 0.8460\n",
      "Epoch 336/400\n",
      "1000/1000 [==============================] - 1s 777us/sample - loss: 0.2723 - accuracy: 0.8483\n",
      "Epoch 337/400\n",
      "1000/1000 [==============================] - 1s 765us/sample - loss: 0.2782 - accuracy: 0.8433\n",
      "Epoch 338/400\n",
      "1000/1000 [==============================] - 1s 766us/sample - loss: 0.2803 - accuracy: 0.8440\n",
      "Epoch 339/400\n",
      "1000/1000 [==============================] - 1s 778us/sample - loss: 0.2811 - accuracy: 0.8433\n",
      "Epoch 340/400\n",
      "1000/1000 [==============================] - 1s 753us/sample - loss: 0.2974 - accuracy: 0.8316\n",
      "Epoch 341/400\n",
      "1000/1000 [==============================] - 1s 984us/sample - loss: 0.3103 - accuracy: 0.8298\n",
      "Epoch 342/400\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.2934 - accuracy: 0.8313\n",
      "Epoch 343/400\n",
      "1000/1000 [==============================] - 1s 894us/sample - loss: 0.2729 - accuracy: 0.8471\n",
      "Epoch 344/400\n",
      "1000/1000 [==============================] - 1s 934us/sample - loss: 0.2750 - accuracy: 0.8466\n",
      "Epoch 345/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2720 - accuracy: 0.8471\n",
      "Epoch 346/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2735 - accuracy: 0.8449\n",
      "Epoch 347/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2714 - accuracy: 0.8503\n",
      "Epoch 348/400\n",
      "1000/1000 [==============================] - 1s 933us/sample - loss: 0.2785 - accuracy: 0.8434\n",
      "Epoch 349/400\n",
      "1000/1000 [==============================] - 1s 971us/sample - loss: 0.2789 - accuracy: 0.8428\n",
      "Epoch 350/400\n",
      "1000/1000 [==============================] - 1s 840us/sample - loss: 0.2886 - accuracy: 0.8403\n",
      "Epoch 351/400\n",
      "1000/1000 [==============================] - 1s 834us/sample - loss: 0.2899 - accuracy: 0.8373\n",
      "Epoch 352/400\n",
      "1000/1000 [==============================] - 1s 993us/sample - loss: 0.3493 - accuracy: 0.8128\n",
      "Epoch 353/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.3079 - accuracy: 0.8286\n",
      "Epoch 354/400\n",
      "1000/1000 [==============================] - 1s 858us/sample - loss: 0.2948 - accuracy: 0.8403\n",
      "Epoch 355/400\n",
      "1000/1000 [==============================] - 1s 870us/sample - loss: 0.2863 - accuracy: 0.8416\n",
      "Epoch 356/400\n",
      "1000/1000 [==============================] - 1s 783us/sample - loss: 0.2821 - accuracy: 0.8404\n",
      "Epoch 357/400\n",
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.2718 - accuracy: 0.8483\n",
      "Epoch 358/400\n",
      "1000/1000 [==============================] - 1s 892us/sample - loss: 0.2647 - accuracy: 0.8542\n",
      "Epoch 359/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2691 - accuracy: 0.8503\n",
      "Epoch 360/400\n",
      "1000/1000 [==============================] - 1s 1ms/sample - loss: 0.2653 - accuracy: 0.8554\n",
      "Epoch 361/400\n",
      "1000/1000 [==============================] - 1s 938us/sample - loss: 0.2635 - accuracy: 0.8523\n",
      "Epoch 362/400\n",
      "1000/1000 [==============================] - 1s 789us/sample - loss: 0.2771 - accuracy: 0.8462\n",
      "Epoch 363/400\n",
      "1000/1000 [==============================] - 1s 872us/sample - loss: 0.2722 - accuracy: 0.8515\n",
      "Epoch 364/400\n",
      "1000/1000 [==============================] - 1s 949us/sample - loss: 0.2648 - accuracy: 0.8526\n",
      "Epoch 365/400\n",
      "1000/1000 [==============================] - 1s 780us/sample - loss: 0.2673 - accuracy: 0.8532\n",
      "Epoch 366/400\n",
      "1000/1000 [==============================] - 1s 807us/sample - loss: 0.3101 - accuracy: 0.8317\n",
      "Epoch 367/400\n",
      "1000/1000 [==============================] - 1s 836us/sample - loss: 0.5742 - accuracy: 0.7464\n",
      "Epoch 368/400\n",
      "1000/1000 [==============================] - 1s 820us/sample - loss: 0.3672 - accuracy: 0.8050\n",
      "Epoch 369/400\n",
      "1000/1000 [==============================] - 1s 790us/sample - loss: 0.2976 - accuracy: 0.8343\n",
      "Epoch 370/400\n",
      "1000/1000 [==============================] - 1s 792us/sample - loss: 0.2657 - accuracy: 0.8545\n",
      "Epoch 371/400\n",
      "1000/1000 [==============================] - 1s 753us/sample - loss: 0.2605 - accuracy: 0.8563\n",
      "Epoch 372/400\n",
      "1000/1000 [==============================] - 1s 768us/sample - loss: 0.2622 - accuracy: 0.8570\n",
      "Epoch 373/400\n",
      "1000/1000 [==============================] - 1s 751us/sample - loss: 0.2559 - accuracy: 0.8598\n",
      "Epoch 374/400\n",
      "1000/1000 [==============================] - 1s 760us/sample - loss: 0.2586 - accuracy: 0.8576\n",
      "Epoch 375/400\n",
      "1000/1000 [==============================] - 1s 744us/sample - loss: 0.2590 - accuracy: 0.8557\n",
      "Epoch 376/400\n",
      "1000/1000 [==============================] - 1s 749us/sample - loss: 0.2592 - accuracy: 0.8583\n",
      "Epoch 377/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 728us/sample - loss: 0.2545 - accuracy: 0.8567\n",
      "Epoch 378/400\n",
      "1000/1000 [==============================] - 1s 756us/sample - loss: 0.2620 - accuracy: 0.8554\n",
      "Epoch 379/400\n",
      "1000/1000 [==============================] - 1s 764us/sample - loss: 0.2857 - accuracy: 0.8502\n",
      "Epoch 380/400\n",
      "1000/1000 [==============================] - 1s 776us/sample - loss: 0.2641 - accuracy: 0.8568\n",
      "Epoch 381/400\n",
      "1000/1000 [==============================] - 1s 758us/sample - loss: 0.2573 - accuracy: 0.8600\n",
      "Epoch 382/400\n",
      "1000/1000 [==============================] - 1s 755us/sample - loss: 0.2550 - accuracy: 0.8601\n",
      "Epoch 383/400\n",
      "1000/1000 [==============================] - 1s 739us/sample - loss: 0.2518 - accuracy: 0.8636\n",
      "Epoch 384/400\n",
      "1000/1000 [==============================] - 1s 740us/sample - loss: 0.2571 - accuracy: 0.8562\n",
      "Epoch 385/400\n",
      "1000/1000 [==============================] - 1s 744us/sample - loss: 0.2559 - accuracy: 0.8632\n",
      "Epoch 386/400\n",
      "1000/1000 [==============================] - 1s 753us/sample - loss: 0.2537 - accuracy: 0.8613\n",
      "Epoch 387/400\n",
      "1000/1000 [==============================] - 1s 749us/sample - loss: 0.2809 - accuracy: 0.8494\n",
      "Epoch 388/400\n",
      "1000/1000 [==============================] - 1s 760us/sample - loss: 0.2978 - accuracy: 0.8368\n",
      "Epoch 389/400\n",
      "1000/1000 [==============================] - 1s 751us/sample - loss: 0.2930 - accuracy: 0.8393\n",
      "Epoch 390/400\n",
      "1000/1000 [==============================] - 1s 756us/sample - loss: 0.2598 - accuracy: 0.8587\n",
      "Epoch 391/400\n",
      "1000/1000 [==============================] - 1s 752us/sample - loss: 0.2562 - accuracy: 0.8600\n",
      "Epoch 392/400\n",
      "1000/1000 [==============================] - 1s 750us/sample - loss: 0.2613 - accuracy: 0.8570\n",
      "Epoch 393/400\n",
      "1000/1000 [==============================] - 1s 759us/sample - loss: 0.2565 - accuracy: 0.8588\n",
      "Epoch 394/400\n",
      "1000/1000 [==============================] - 1s 743us/sample - loss: 0.2545 - accuracy: 0.8587\n",
      "Epoch 395/400\n",
      "1000/1000 [==============================] - 1s 735us/sample - loss: 0.2477 - accuracy: 0.8648\n",
      "Epoch 396/400\n",
      "1000/1000 [==============================] - 1s 753us/sample - loss: 0.2466 - accuracy: 0.8679\n",
      "Epoch 397/400\n",
      "1000/1000 [==============================] - 1s 754us/sample - loss: 0.2499 - accuracy: 0.8633\n",
      "Epoch 398/400\n",
      "1000/1000 [==============================] - 1s 763us/sample - loss: 0.2447 - accuracy: 0.8674\n",
      "Epoch 399/400\n",
      "1000/1000 [==============================] - 1s 758us/sample - loss: 0.2467 - accuracy: 0.8675\n",
      "Epoch 400/400\n",
      "1000/1000 [==============================] - 1s 757us/sample - loss: 0.2470 - accuracy: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x135588748>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=n_epoch, batch_size=n_batch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculation Performance in MSE : 0.310371\n",
      "Show some specific examples\n",
      "Input =11.21875+3.46875, Expected=14.6875, Predicted=14.5\n",
      "Input =3.5+16.34375, Expected=19.84375, Predicted=19.5\n",
      "Input =15.375+12.375, Expected=27.75, Predicted=27.875\n",
      "Input =10.3125+16.28125, Expected=26.59375, Predicted=26.75\n",
      "Input =4.4375+4.25, Expected=8.6875, Predicted=8.71875\n",
      "Input =9.21875+14.4375, Expected=23.65625, Predicted=23.5\n",
      "Input =16.21875+8.125, Expected=24.34375, Predicted=24.5\n",
      "Input =13.03125+11.0625, Expected=24.09375, Predicted=24.40625\n",
      "Input =8.21875+3.34375, Expected=11.5625, Predicted=11.46875\n",
      "Input =4.03125+13.5, Expected=17.53125, Predicted=17.84375\n",
      "Input =7.21875+13.09375, Expected=20.3125, Predicted=20.21875\n",
      "Input =11.3125+2.4375, Expected=13.75, Predicted=13.59375\n",
      "Input =4.5+9.09375, Expected=13.59375, Predicted=13.5\n",
      "Input =5.46875+2.125, Expected=7.59375, Predicted=7.78125\n",
      "Input =12.34375+6.40625, Expected=18.75, Predicted=18.625\n",
      "Input =14.46875+6.1875, Expected=20.65625, Predicted=20.75\n",
      "Input =4.40625+7.03125, Expected=11.4375, Predicted=11.46875\n",
      "Input =1.15625+14.25, Expected=15.40625, Predicted=15.40625\n",
      "Input =1.125+9.0625, Expected=10.1875, Predicted=10.4375\n",
      "Input =1.40625+15.125, Expected=16.53125, Predicted=16.5\n",
      "Input =2.03125+5.0625, Expected=7.09375, Predicted=4.4375\n",
      "Input =7.15625+14.40625, Expected=21.5625, Predicted=21.53125\n",
      "Input =14.5+11.09375, Expected=25.59375, Predicted=25.40625\n",
      "Input =1.21875+12.40625, Expected=13.625, Predicted=13.5\n",
      "Input =8.1875+4.34375, Expected=12.53125, Predicted=12.59375\n",
      "Input =16.28125+4.0625, Expected=20.34375, Predicted=20.0\n",
      "Input =2.125+12.03125, Expected=14.15625, Predicted=14.125\n",
      "Input =7.0625+7.125, Expected=14.1875, Predicted=14.1875\n",
      "Input =7.28125+13.03125, Expected=20.3125, Predicted=20.21875\n",
      "Input =12.15625+8.28125, Expected=20.4375, Predicted=20.21875\n",
      "Input =12.4375+14.0625, Expected=26.5, Predicted=26.625\n",
      "Input =13.40625+5.25, Expected=18.65625, Predicted=18.625\n",
      "Input =12.5+5.125, Expected=17.625, Predicted=17.5\n",
      "Input =2.15625+5.375, Expected=7.53125, Predicted=7.53125\n",
      "Input =6.40625+1.09375, Expected=7.5, Predicted=3.28125\n",
      "Input =5.25+9.15625, Expected=14.40625, Predicted=14.5\n",
      "Input =11.4375+12.15625, Expected=23.59375, Predicted=23.625\n",
      "Input =8.25+13.4375, Expected=21.6875, Predicted=21.5625\n",
      "Input =15.28125+3.5, Expected=18.78125, Predicted=18.65625\n",
      "Input =8.21875+9.40625, Expected=17.625, Predicted=17.625\n",
      "Input =5.25+8.21875, Expected=13.46875, Predicted=13.5625\n",
      "Input =11.375+7.09375, Expected=18.46875, Predicted=18.84375\n",
      "Input =4.25+1.03125, Expected=5.28125, Predicted=5.1875\n",
      "Input =3.1875+16.46875, Expected=19.65625, Predicted=19.625\n",
      "Input =4.4375+2.3125, Expected=6.75, Predicted=6.78125\n",
      "Input =4.09375+13.125, Expected=17.21875, Predicted=17.25\n",
      "Input =16.28125+5.5, Expected=21.78125, Predicted=21.71875\n",
      "Input =7.4375+7.40625, Expected=14.84375, Predicted=14.5\n",
      "Input =16.40625+9.1875, Expected=25.59375, Predicted=25.6875\n",
      "Input =5.09375+1.09375, Expected=6.1875, Predicted=6.1875\n"
     ]
    }
   ],
   "source": [
    "#evaluate on some new patterns\n",
    "n_samples = 100\n",
    "X_test, y_test = generate_data(n_samples, n_numbers, largest, alphabet)\n",
    "# convert input to float32 to match the ops datatype\n",
    "X_test = X_test.astype(np.float32)\n",
    "pred = model.predict(X_test, batch_size=n_batch, verbose=0)\n",
    "# calculate error\n",
    "X_test_invert = [invert(x, alphabet) for x in X_test]\n",
    "expected = [float(invert(x, alphabet)) for x in y_test]\n",
    "predicted = [float(invert(x, alphabet)) for x in pred]\n",
    "mse = ((np.array(expected) - np.array(predicted))**2).mean(axis=0)\n",
    "print(\"Calculation Performance in MSE : %.6f\" % mse)\n",
    "print(\"Show some specific examples\")\n",
    "for i in range(50):\n",
    "    print('Input =%s, Expected=%s, Predicted=%s' % (X_test_invert[i], expected[i], predicted[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comment on LSTM vs. GRU models \n",
    "# The GRU model trained faster than the LSTM.\n",
    "# When it comes to testing, the GRU model performs better than the LSTM as well. \n",
    "# This can be seen from the comparison of the MSE values for each model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
